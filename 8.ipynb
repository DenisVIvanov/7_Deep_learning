{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dll_hw_8_10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CDNF5crkbNj-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dviva1972/denvlaiva/blob/master/dll_hw_8_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDgFV2qNmj7Z"
      },
      "source": [
        "## DLL\n",
        "\n",
        "## Домашняя работа 8 | Attention\n",
        "\n",
        "## Иванов Денис"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfjxV1j_O6Ud"
      },
      "source": [
        "Решить задачу перевода с помощью механизме внимания\n",
        "\n",
        "Возьмите англо-русскую пару фраз (www.manythings.org....org/anki/)\n",
        "\n",
        "Обучите на них seq2seq with attention\n",
        "\n",
        "a. На основе скалярного произведения\n",
        "\n",
        "b. На основе MLP\n",
        "\n",
        "Оцените качество"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbp9AnjfbCTf"
      },
      "source": [
        "### 1. Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIEGXF8oM9tt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "from   itertools import product\n",
        "import unicodedata\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from   torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2u0oq5spS83"
      },
      "source": [
        "# Visualisation\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "plt.switch_backend('agg')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTVkH1myZyrY"
      },
      "source": [
        "from io import open\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkKa2S1so4jE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6888c8f9-7dbf-42b8-f28f-5a0ba40bd67c"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDNF5crkbNj-"
      },
      "source": [
        "### 2. Импорт и предобработка текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UKlPFcBNZl5",
        "outputId": "49929bc8-335e-4842-8b46-2bfa4222f27b"
      },
      "source": [
        "!wget https://www.manythings.org/anki/rus-eng.zip\n",
        "!unzip rus-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-27 07:04:38--  https://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.186.54, 104.21.92.44, 2606:4700:3033::ac43:ba36, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.186.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14385451 (14M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  13.72M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-09-27 07:04:39 (147 MB/s) - ‘rus-eng.zip’ saved [14385451/14385451]\n",
            "\n",
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twIcAJnyRkW-",
        "outputId": "651dc762-ab0b-4d4e-c829-c933da25e4f7"
      },
      "source": [
        "!tail rus.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The more countries a language is spoken in, the less important it is to sound like a native speaker, since speakers of that language are accustomed to hearing various dialects.\tЧем в большем количестве стран используется тот или иной язык, тем менее важно иметь такое же произношение, как у его носителей, так как носители этого языка привыкли к звучанию различных акцентов.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954354 (CK) & #4465953 (Wezel)\n",
            "A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\tОшибка, которую часто делают молодые, — начинают учить слишком много языков одновременно: они недооценивают трудности и переоценивают свои способности к изучению.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2783162 (catcher) & #5118905 (Wezel)\n",
            "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (CO) & #6390439 (odexed)\n",
            "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (CO) & #6390123 (odexed)\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (CO) & #5968115 (odexed)\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (CO) & #4509418 (odexed)\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
            "It's so easy to write good example sentences, that even if we accidentally delete a few good sentences in the process of getting rid of a whole lot of bad ones, I think we could drastically improve the quality of this corpus by doing a lot of deleting.\tСоздавать хорошие предложения-примеры так легко, что даже если мы случайно удалим несколько хороших предложений в процессе избавления от кучи плохих, думаю, мы могли бы заметно улучшить качество этого корпуса, удаляя в больших количествах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #933897 (CK) & #3689230 (Ooneykcall)\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g94K3e3lqswm"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "lang1 = 'eng'\n",
        "lang2 = 'rus'\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnnqsLRRqss2"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Zа-яА-ЯёЁ.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY0bxTQXqspg"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('rus.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    for p in pairs:\n",
        "        del p[2]\n",
        "    \n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1akHIbmYqsjg"
      },
      "source": [
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p, prefi, max_): ##############\n",
        "    if prefi == None:\n",
        "        return  len(p[0].split(' ')) >3 and \\\n",
        "                len(p[1].split(' ')) >3 and \\\n",
        "                len(p[0].split(' ')) < max_ and \\\n",
        "                len(p[1].split(' ')) < max_ \n",
        "    else:\n",
        "        return  len(p[0].split(' ')) >3 and \\\n",
        "                len(p[1].split(' ')) >3 and \\\n",
        "                len(p[0].split(' ')) < max_ and \\\n",
        "                len(p[1].split(' ')) < max_ and \\\n",
        "                p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs, pref, max_l):\n",
        "    return [pair for pair in pairs if filterPair(pair, pref, max_l)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdiIFtCaqsgP",
        "outputId": "4c202c71-3482-4f79-c61f-62848429bc14"
      },
      "source": [
        "def prepareData(lang1, lang2, pre, max_le,  reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs, pre, max_le)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', None, 20, True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 431097 sentence pairs\n",
            "Trimmed to 409735 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 52630\n",
            "eng 15912\n",
            "['занятия в школе начинаются в девять а заканчиваются в шесть .', 'school begins at nine and is over at six .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xax3SDBKb17_"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair, input_l, output_l):\n",
        "    input_tensor = tensorFromSentence(input_l, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_l, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1y41t4wbZlM"
      },
      "source": [
        "### 3. Архитектура сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgtWqznCM9uH"
      },
      "source": [
        "#### 3.1. Encoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqukGu_qSGW9"
      },
      "source": [
        "class EncoderRNN2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, rnn_type):\n",
        "        super(EncoderRNN2, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding   = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn         = rnn_type(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded         = self.embedding(input).view(1, 1, -1)\n",
        "        output           = embedded\n",
        "        output, hidden   = self.rnn(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwLTlgSyM9uK"
      },
      "source": [
        "#### 3.2. Decoder - 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qR8FKQZRmQm"
      },
      "source": [
        "class AttnDecoderRNN_mlp(nn.Module): \n",
        "    def __init__(self, hidden_size, output_size, rnn_type, m_length,\n",
        "                 dropout_p=0.1):\n",
        "        super(AttnDecoderRNN_mlp, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p   = dropout_p\n",
        "        self.max_length  = m_length\n",
        "        \n",
        "        self.embedding   = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn        = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine= nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout     = nn.Dropout(self.dropout_p)\n",
        "        self.rnn         = rnn_type(hidden_size, hidden_size)\n",
        "        self.out         = nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.rnn_t_n     = rnn_type.__name__\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "        embedded         = self.embedding(input).view(1, 1, -1)        \n",
        "        embedded         = self.dropout(embedded)\n",
        "\n",
        "        if self.rnn_t_n == 'LSTM':\n",
        "            attn_weights     = F.softmax(self.attn(torch.cat(\n",
        "                                        (embedded[0], hidden[0][0]), 1)), dim=1)  \n",
        "        else:\n",
        "            attn_weights     = F.softmax(self.attn(torch.cat(\n",
        "                                        (embedded[0], hidden[0]), 1)), dim=1) \n",
        "             \n",
        "        attn_applied     = torch.bmm( attn_weights.unsqueeze(0),\n",
        "                                      encoder_outputs.unsqueeze(0))\n",
        "        output           = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output           = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output           = F.relu(output)\n",
        "        output, hidden   = self.rnn(output, hidden)\n",
        "        \n",
        "        output           = F.log_softmax(self.out(output[0]), dim=1)        \n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsmnpN2bcq0y"
      },
      "source": [
        "#### 3.3. Decoder - 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkS1uWk93EXX"
      },
      "source": [
        "class AttnDecoderRNN_scalar(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, rnn_type, m_length,\n",
        "                 dropout_p=0.1):\n",
        "        super(AttnDecoderRNN_scalar, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p   = dropout_p\n",
        "        self.max_length  = m_length\n",
        "\n",
        "        self.embedding   = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn        = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine= nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout     = nn.Dropout(self.dropout_p)\n",
        "        self.rnn         = rnn_type(hidden_size, hidden_size)\n",
        "        self.out         = nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.rnn_t_n     = rnn_type.__name__\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "            \n",
        "        embedded         = self.embedding(input).view(1, 1, -1)\n",
        "        embedded         = self.dropout(embedded)        \n",
        "\n",
        "        attn_weights     = F.softmax((embedded[0] @ encoder_outputs.T) / \n",
        "                                     self.max_length**0.5, dim=1)\n",
        "        attn_applied     = torch.bmm(attn_weights.unsqueeze(0), \n",
        "                                     encoder_outputs.unsqueeze(0))\n",
        "        \n",
        "        output           = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output           = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output           = F.relu(output)\n",
        "        output, hidden   = self.rnn(output, hidden)\n",
        "\n",
        "        output           = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        \n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWJB9sIqeG4e"
      },
      "source": [
        "#### 3.4. Train + Teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fn8VDv8M9uS"
      },
      "source": [
        "def train(input_tens, target_tens, \n",
        "          encode, decode, encode_optimizer, decode_optimizer, \n",
        "          criteri, m__length, rnn_ty,  t_f_ratio):\n",
        "    \n",
        "    \n",
        "    if rnn_ty.__name__ == 'LSTM':\n",
        "        encoder_hidden = (encode.initHidden(), encode.initHidden())\n",
        "    else:\n",
        "        encoder_hidden = encode.initHidden()\n",
        "\n",
        "    encode_optimizer.zero_grad()\n",
        "    decode_optimizer.zero_grad()\n",
        "\n",
        "    input_length       = input_tens.size(0)\n",
        "    target_length      = target_tens.size(0)\n",
        "\n",
        "    encoder_outputs    = torch.zeros(m__length, encode.hidden_size, \n",
        "                                     device=device)\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encode(\n",
        "                                            input_tens[ei], encoder_hidden)\n",
        "        encoder_outputs[ei]            = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input       = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden      = encoder_hidden\n",
        "    \n",
        "    use_teacher_forcing = True if random.random() < t_f_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decode(\n",
        "                                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criteri(decoder_output, target_tens[di])\n",
        "            decoder_input = target_tens[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decode(\n",
        "                                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criteri(decoder_output, target_tens[di])\n",
        "            if decoder_input.item() == EOS_token: ##\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encode_optimizer.step()\n",
        "    decode_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLEY3Vv9egYf"
      },
      "source": [
        "#### 3.5. Train + iters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_z_k5IiM9uX"
      },
      "source": [
        "def trainIters(pair_sentenses, encoder, decoder, learning_rate, \n",
        "               n_iters, MAX_LENGTH, rnn_typ, teach_f_ratio, input_lan, output_lan,\n",
        "               print_every=5000, plot_every=500):\n",
        "    \n",
        "    start             = time.time()\n",
        "    plot_losses       = []\n",
        "    print_loss_total  = 0  # Reset every print_every\n",
        "    plot_loss_total   = 0  # Reset every plot_every\n",
        "    print_loss_avg=0\n",
        "    print_loss_total_abs=0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    training_pairs = [tensorsFromPair(random.choice(pair_sentenses), \n",
        "                                      input_lan, output_lan)\n",
        "                                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, \n",
        "                     encoder_optimizer, decoder_optimizer, criterion, \n",
        "                     MAX_LENGTH, rnn_typ,  teach_f_ratio)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total  += loss\n",
        "        print_loss_total_abs += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses) ##\n",
        "    return print_loss_avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6krQ6s2euzs"
      },
      "source": [
        "#### 3.6. Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bxf45h6M9ud"
      },
      "source": [
        "def evaluate(encode, decode, sentence, max_length, Rnn, inp_lang, out_lang):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(inp_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "\n",
        "        if Rnn.__name__ == 'LSTM':\n",
        "            encoder_hidden = (encode.initHidden(), encode.initHidden())\n",
        "        else:\n",
        "            encoder_hidden = encode.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encode.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encode(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  \n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "        \n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decode(\n",
        "                                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(out_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qUmQIGwM9uf"
      },
      "source": [
        "def evaluateRandomly(pair_sen, encoder, decoder, MAX_LENGTH, \n",
        "                     rnn_, in_lang, o_lang,  n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pair_sen)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0], MAX_LENGTH,  # output_words, attentions\n",
        "                                            rnn_, in_lang, o_lang)[0]\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGykVYN2dXVf"
      },
      "source": [
        "#### 3.7. Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsdwPmSM9uU"
      },
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecxd1Bo_1iuG"
      },
      "source": [
        "def fine_table(table, title = None, x_l=None, y_l = None, \n",
        "               ):\n",
        "    p_t = table\n",
        "    fig, ax = plt.subplots(figsize=(12,4))\n",
        "    sns.heatmap(p_t, \n",
        "                annot = True, \n",
        "                fmt ='.3', \n",
        "                cmap= 'YlGnBu', \n",
        "                linewidths=0.1, \n",
        "                linecolor='black'\n",
        "                )\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=45)\n",
        "    plt.xlabel(x_l)\n",
        "    plt.ylabel(y_l)\n",
        "    plt.title(title)\n",
        "    i, k = ax.get_ylim()\n",
        "    ax.set_ylim(i+0.5, k-0.5)\n",
        "    plt.show()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msFzE3vEdiUr"
      },
      "source": [
        "### 4. Обучение "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6NXeEdM9-xf"
      },
      "source": [
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "rnn_types           = [nn.LSTM, \n",
        "                       nn.RNN, \n",
        "                       nn.GRU,] \n",
        "cols                = ['Max_length', 'RNN_Type', 'Hidden_layers', 'Decoder', 'Loss']\n",
        "\n",
        "PATH8               = '/content/drive/My Drive/DLL/else/df_8_'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxdFS2c1Ea-g"
      },
      "source": [
        "def test_model_hw_8(max_length_sent, prefix, hidden_size = 256,\n",
        "                    learn_rate = 0.01, \n",
        "                    teach_force_ratio = 0.5, \n",
        "                    num_iters = 50000,  every = 1000, num_file = 999):\n",
        "    \n",
        "    input_lang_, output_lang_, pair_s = prepareData('eng', 'rus', prefix, \n",
        "                                                    max_length_sent,\n",
        "                                                    True)\n",
        "    \n",
        "    print(random.choice(pair_s))\n",
        "    \n",
        "    df = pd.DataFrame(columns= cols)\n",
        "\n",
        "    for rnn_type, decoder_ in product(rnn_types, range(2)):\n",
        "        \n",
        "        print('\\nMax_length = ', max_length_sent)  \n",
        "        print('\\nDecoder = ', decoder_ + 1)                       \n",
        "        print(f'{rnn_type.__name__}\\n\\ntraining')\n",
        "\n",
        "        encoder2 = EncoderRNN2(input_lang_.n_words, hidden_size, rnn_type\n",
        "                               ).to(device)\n",
        "\n",
        "        att_dec_mllp  = AttnDecoderRNN_mlp(hidden_size, output_lang_.n_words, \n",
        "                                            rnn_type, \n",
        "                                           max_length_sent,dropout_p=0.1\n",
        "                                           ).to(device)\n",
        "        att_dec_scalar = AttnDecoderRNN_scalar(hidden_size, output_lang_.n_words, \n",
        "                                               rnn_type, \n",
        "                                               max_length_sent, dropout_p=0.1\n",
        "                                               ).to(device)\n",
        "\n",
        "        d_list         = [att_dec_mllp, att_dec_scalar]\n",
        "        d_text         = str(d_list[decoder_])\n",
        "\n",
        "        loss_= trainIters(pair_s, encoder2, d_list[decoder_], \n",
        "                          learn_rate, num_iters, \n",
        "                          max_length_sent,  rnn_type, teach_force_ratio, \n",
        "                          input_lang_, output_lang_, every)\n",
        "\n",
        "        \n",
        "        print('\\nevaluate\\n')\n",
        "        evaluateRandomly(pair_s, encoder2, d_list[decoder_], max_length_sent, \n",
        "                         rnn_type, input_lang_, output_lang_)\n",
        "        \n",
        "      \n",
        "        string     = [max_length_sent, rnn_type.__name__, 0, d_text, loss_]\n",
        "        df.loc[len(df)] = string\n",
        "        file_name  = PATH8 + str(num_file) + '.csv'\n",
        "        df.to_csv(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksVzm5ezfDCa"
      },
      "source": [
        "#### 4.1.  Модель 1 - Предложения по шаблону eng_prefixes от 3 до 20 слов / lr = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIdEZ2CGVnK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffd20e7-e91c-4542-a7a0-45490c4c74a2"
      },
      "source": [
        "test_model_hw_8(max_length_sent = 20, prefix = eng_prefixes, \n",
        "                learn_rate = 0.05, teach_force_ratio = 0.5,                 \n",
        "                num_iters = 75000,  every = 5000, num_file = 'Att1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 431097 sentence pairs\n",
            "Trimmed to 26677 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 9867\n",
            "eng 4161\n",
            "['я беру неделю отпуска .', 'i m taking a week off .']\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 17s (- 17m 59s) (5000 6%) 3.1931\n",
            "2m 31s (- 16m 22s) (10000 13%) 2.7342\n",
            "3m 45s (- 15m 1s) (15000 20%) 2.4923\n",
            "5m 0s (- 13m 46s) (20000 26%) 2.3360\n",
            "6m 15s (- 12m 30s) (25000 33%) 2.2123\n",
            "7m 31s (- 11m 16s) (30000 40%) 2.1255\n",
            "8m 46s (- 10m 1s) (35000 46%) 2.0332\n",
            "10m 2s (- 8m 47s) (40000 53%) 1.9793\n",
            "11m 17s (- 7m 31s) (45000 60%) 1.9107\n",
            "12m 32s (- 6m 16s) (50000 66%) 1.8604\n",
            "13m 48s (- 5m 1s) (55000 73%) 1.7932\n",
            "15m 3s (- 3m 45s) (60000 80%) 1.7670\n",
            "16m 18s (- 2m 30s) (65000 86%) 1.6771\n",
            "17m 34s (- 1m 15s) (70000 93%) 1.6472\n",
            "18m 49s (- 0m 0s) (75000 100%) 1.6301\n",
            "\n",
            "evaluate\n",
            "\n",
            "> я не в состоянии об этом дискутировать .\n",
            "= i m not in a position to discuss that .\n",
            "< i m not in about about about . . <EOS>\n",
            "\n",
            "> я вас покидаю .\n",
            "= i m leaving you .\n",
            "< i m going you . . <EOS>\n",
            "\n",
            "> я начинаю думать что вы правы .\n",
            "= i m beginning to think you re right .\n",
            "< i m starting to think you re . . <EOS>\n",
            "\n",
            "> я тебе очень благодарна .\n",
            "= i m very grateful to you .\n",
            "< i m very grateful to you . <EOS>\n",
            "\n",
            "> я начинаю нервничать .\n",
            "= i m getting nervous .\n",
            "< i m starting to . . <EOS>\n",
            "\n",
            "> он не тот человек которому можно доверять .\n",
            "= he is not a man to be trusted .\n",
            "< he s not man man man man man . <EOS>\n",
            "\n",
            "> я никому не нужен .\n",
            "= i m no use to anyone .\n",
            "< i m not going with anything . <EOS>\n",
            "\n",
            "> мне все нравится .\n",
            "= i m happy with everything .\n",
            "< i m all to . <EOS>\n",
            "\n",
            "> я планирую пробыть здесь три дня .\n",
            "= i m planning to be here for three days .\n",
            "< i m planning back for a here . . <EOS>\n",
            "\n",
            "> бог наградил меня хорошим здоровьем .\n",
            "= i am blessed with good health .\n",
            "< i m tired of hearing . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 15s (- 17m 40s) (5000 6%) 3.2488\n",
            "2m 28s (- 16m 7s) (10000 13%) 2.7377\n",
            "3m 42s (- 14m 49s) (15000 20%) 2.4959\n",
            "4m 55s (- 13m 33s) (20000 26%) 2.3005\n",
            "6m 8s (- 12m 17s) (25000 33%) 2.1841\n",
            "7m 21s (- 11m 2s) (30000 40%) 2.1307\n",
            "8m 34s (- 9m 47s) (35000 46%) 2.0456\n",
            "9m 46s (- 8m 33s) (40000 53%) 2.0075\n",
            "10m 59s (- 7m 19s) (45000 60%) 1.9634\n",
            "12m 13s (- 6m 6s) (50000 66%) 1.8593\n",
            "13m 27s (- 4m 53s) (55000 73%) 1.8390\n",
            "14m 41s (- 3m 40s) (60000 80%) 1.7553\n",
            "15m 54s (- 2m 26s) (65000 86%) 1.7244\n",
            "17m 7s (- 1m 13s) (70000 93%) 1.6763\n",
            "18m 20s (- 0m 0s) (75000 100%) 1.6841\n",
            "\n",
            "evaluate\n",
            "\n",
            "> я не уверен что это сделал том .\n",
            "= i m not sure it was tom who did that .\n",
            "< i m not sure that tom is wrong . <EOS>\n",
            "\n",
            "> рад слышать что тебе лучше .\n",
            "= i m glad to hear that you re getting better .\n",
            "< i m glad to hear you re better . <EOS>\n",
            "\n",
            "> мы ищем хорошии дом для жизни .\n",
            "= we re looking for a nice house to live in .\n",
            "< we re looking for a a a . . . . <EOS>\n",
            "\n",
            "> она в шляпе .\n",
            "= she is wearing a hat .\n",
            "< she is in . . . <EOS>\n",
            "\n",
            "> я еще не привык к здешнеи еде .\n",
            "= i m still not used to the food here .\n",
            "< i m not used to this sort of food . <EOS>\n",
            "\n",
            "> несомненно ты в замешательстве том .\n",
            "= you re no doubt confused tom .\n",
            "< you re going to . . . . <EOS>\n",
            "\n",
            "> она редко если вообще выходит после того как стемнеет .\n",
            "= she seldom if ever goes out after dark .\n",
            "< she is sure a ever as his parents as his . . <EOS>\n",
            "\n",
            "> мы остаемся здесь .\n",
            "= we re staying here .\n",
            "< we re here here . <EOS>\n",
            "\n",
            "> я так рада что ты позвонила .\n",
            "= i m so glad you called .\n",
            "< i m so happy you you the . . <EOS>\n",
            "\n",
            "> мы до сих пор лучшие друзья .\n",
            "= we re still the best of friends .\n",
            "< we re still alive . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "RNN\n",
            "\n",
            "training\n",
            "1m 12s (- 16m 58s) (5000 6%) 18.7270\n",
            "2m 22s (- 15m 25s) (10000 13%) 21.3499\n",
            "3m 31s (- 14m 7s) (15000 20%) 22.0138\n",
            "4m 41s (- 12m 54s) (20000 26%) 22.1034\n",
            "5m 51s (- 11m 42s) (25000 33%) 21.6150\n",
            "7m 0s (- 10m 30s) (30000 40%) 23.9371\n",
            "8m 9s (- 9m 19s) (35000 46%) 25.0080\n",
            "9m 19s (- 8m 9s) (40000 53%) 25.3633\n",
            "10m 29s (- 6m 59s) (45000 60%) 24.6133\n",
            "11m 38s (- 5m 49s) (50000 66%) 25.1519\n",
            "12m 46s (- 4m 38s) (55000 73%) 25.0497\n",
            "13m 57s (- 3m 29s) (60000 80%) 25.2015\n",
            "15m 6s (- 2m 19s) (65000 86%) 25.3637\n",
            "16m 16s (- 1m 9s) (70000 93%) 25.2833\n",
            "17m 24s (- 0m 0s) (75000 100%) 24.6551\n",
            "\n",
            "evaluate\n",
            "\n",
            "> вы немного выше меня .\n",
            "= you re a bit taller than i am .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> вы последнии человек которого я ожидал здесь увидеть .\n",
            "= you re the last person i would ve expected to see here .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> он за мнои наблюдает .\n",
            "= he s watching me .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> боюсь кофе не осталось .\n",
            "= i m afraid that there isn t any coffee left .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> я очень молодои по сравнению с томом .\n",
            "= i m very young compared to tom .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> мы не собираемся ждать тома .\n",
            "= we re not going to wait for tom .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> ты такая разборчивая !\n",
            "= you re so picky .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> мы здесь закончили .\n",
            "= we re finished here .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> я есть не хочу а пить хочу .\n",
            "= i m not hungry but i m thirsty .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "> у нас все в порядке .\n",
            "= we re all right .\n",
            "< out out out out out out out out out out out out out out out out out out out out\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "RNN\n",
            "\n",
            "training\n",
            "1m 11s (- 16m 41s) (5000 6%) 14.7285\n",
            "2m 20s (- 15m 10s) (10000 13%) 18.1287\n",
            "3m 26s (- 13m 47s) (15000 20%) 18.0160\n",
            "4m 34s (- 12m 34s) (20000 26%) 17.6711\n",
            "5m 41s (- 11m 23s) (25000 33%) 18.9709\n",
            "6m 50s (- 10m 15s) (30000 40%) 21.1724\n",
            "7m 58s (- 9m 7s) (35000 46%) 20.9259\n",
            "9m 6s (- 7m 58s) (40000 53%) 20.8846\n",
            "10m 14s (- 6m 49s) (45000 60%) 19.1311\n",
            "11m 22s (- 5m 41s) (50000 66%) 18.6873\n",
            "12m 30s (- 4m 32s) (55000 73%) 17.8980\n",
            "13m 39s (- 3m 24s) (60000 80%) 17.6031\n",
            "14m 47s (- 2m 16s) (65000 86%) 17.6191\n",
            "15m 55s (- 1m 8s) (70000 93%) 17.6417\n",
            "17m 3s (- 0m 0s) (75000 100%) 17.3774\n",
            "\n",
            "evaluate\n",
            "\n",
            "> я не ученик .\n",
            "= i m not a student .\n",
            "< you trying but trying but trying but trying but more than more than more <EOS>\n",
            "\n",
            "> я не закончила .\n",
            "= i m not done .\n",
            "< you trying but more <EOS>\n",
            "\n",
            "> мне жаль слышать что том болен .\n",
            "= i m sorry to hear tom is sick .\n",
            "< you trying but trying but trying but trying but trying but trying but trying but trying but trying but trying\n",
            "\n",
            "> я ответственныи человек .\n",
            "= i m a responsible person .\n",
            "< you trying but you trying but you trying but trying but trying but trying but you trying but trying but\n",
            "\n",
            "> это вам надо беспокоиться .\n",
            "= you re the one who should be worried .\n",
            "< you trying but you trying but trying but you trying but trying but trying but trying but you trying but\n",
            "\n",
            "> она не сказала ничего такого что могло бы его рассердить .\n",
            "= she said nothing that would make him angry .\n",
            "< you trying trying but trying but trying but trying but trying but trying but trying but you trying but trying\n",
            "\n",
            "> я устал сидеть .\n",
            "= i m tired of sitting .\n",
            "< you trying but trying but trying but more than that trying trying but trying but trying but trying but trying\n",
            "\n",
            "> он сильнее меня .\n",
            "= he s stronger than me .\n",
            "< you trying trying trying trying trying but you trying trying trying trying trying trying trying trying trying trying but trying\n",
            "\n",
            "> я не колдун .\n",
            "= i m not a magician .\n",
            "< you trying but trying but trying but more <EOS>\n",
            "\n",
            "> он вечно на что нибудь жалуется .\n",
            "= he s always complaining about something .\n",
            "< you trying but trying but trying but trying but trying but trying but trying but trying but trying but trying\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 15s (- 17m 37s) (5000 6%) 3.1101\n",
            "2m 26s (- 15m 54s) (10000 13%) 2.9898\n",
            "3m 37s (- 14m 31s) (15000 20%) 14.4286\n",
            "4m 48s (- 13m 13s) (20000 26%) 19.0814\n",
            "5m 59s (- 11m 59s) (25000 33%) 19.7712\n",
            "7m 10s (- 10m 45s) (30000 40%) 20.7173\n",
            "8m 20s (- 9m 31s) (35000 46%) 21.2228\n",
            "9m 30s (- 8m 19s) (40000 53%) 20.9294\n",
            "10m 40s (- 7m 6s) (45000 60%) 20.3869\n",
            "11m 50s (- 5m 55s) (50000 66%) 21.0519\n",
            "12m 59s (- 4m 43s) (55000 73%) 20.0908\n",
            "14m 8s (- 3m 32s) (60000 80%) 19.9499\n",
            "15m 19s (- 2m 21s) (65000 86%) 21.4975\n",
            "16m 30s (- 1m 10s) (70000 93%) 21.0706\n",
            "17m 41s (- 0m 0s) (75000 100%) 22.2332\n",
            "\n",
            "evaluate\n",
            "\n",
            "> ты же не канадка ?\n",
            "= you aren t canadian are you ?\n",
            "< i t t t t t t t t t t t t t t t t t t t\n",
            "\n",
            "> у нас встреча .\n",
            "= we are having a meeting .\n",
            "< i m ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did\n",
            "\n",
            "> я не предлагаю вам это делать .\n",
            "= i m not suggesting you do that .\n",
            "< i only only only only only only only only only only only only only only only only only only only\n",
            "\n",
            "> прости но я не могу ответить прямо сеичас .\n",
            "= i m sorry but i cannot answer right away .\n",
            "< i m ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did\n",
            "\n",
            "> я не такои как том .\n",
            "= i m not like tom .\n",
            "< i about ashamed about ashamed about ashamed about ashamed about ashamed about ashamed about ashamed about ashamed about ashamed about\n",
            "\n",
            "> простите что заставил вас так долго ждать .\n",
            "= i m sorry to have kept you waiting so long .\n",
            "< i happen trust did trust did trust did trust did trust did trust did trust did trust did trust did\n",
            "\n",
            "> извини том . я не могу этого сделать .\n",
            "= i m sorry tom . i can t do this .\n",
            "< i m ashamed about ashamed about ashamed about ashamed about ashamed about ashamed about ashamed about ashamed about ashamed about\n",
            "\n",
            "> я уже в самолете .\n",
            "= i m already on the plane .\n",
            "< i m at did at did at did ashamed did at did at did at did at did at did\n",
            "\n",
            "> я не странная .\n",
            "= i m not weird .\n",
            "< i m ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did ashamed did\n",
            "\n",
            "> я уверен что он поехал в токио .\n",
            "= i m sure that he went to tokyo .\n",
            "< i m sure only sure only sure only sure only sure only ashamed did sure ashamed did sure only sure\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 13s (- 17m 3s) (5000 6%) 3.0928\n",
            "2m 24s (- 15m 36s) (10000 13%) 2.9746\n",
            "3m 35s (- 14m 20s) (15000 20%) 2.9411\n",
            "4m 46s (- 13m 6s) (20000 26%) 2.9401\n",
            "5m 56s (- 11m 53s) (25000 33%) 2.8500\n",
            "7m 6s (- 10m 39s) (30000 40%) 2.7341\n",
            "8m 16s (- 9m 27s) (35000 46%) 2.8209\n",
            "9m 26s (- 8m 15s) (40000 53%) 2.8535\n",
            "10m 35s (- 7m 3s) (45000 60%) 2.7759\n",
            "11m 46s (- 5m 53s) (50000 66%) 2.8851\n",
            "12m 55s (- 4m 41s) (55000 73%) 2.9384\n",
            "14m 5s (- 3m 31s) (60000 80%) 2.8706\n",
            "15m 16s (- 2m 20s) (65000 86%) 3.0000\n",
            "16m 26s (- 1m 10s) (70000 93%) 3.0277\n",
            "17m 37s (- 0m 0s) (75000 100%) 3.1478\n",
            "\n",
            "evaluate\n",
            "\n",
            "> я не вегетарианка .\n",
            "= i m not a vegetarian .\n",
            "< i m not the . <EOS>\n",
            "\n",
            "> мы выходим на следующеи остановке .\n",
            "= we re getting off at the next station .\n",
            "< we re at at home a teacher <EOS>\n",
            "\n",
            "> я думаю о том что мне купить .\n",
            "= i m thinking about what i should buy .\n",
            "< i m thinking about about about about about about about about about about about about about about about about about\n",
            "\n",
            "> теперь я могу сделать это сама .\n",
            "= i m now able to do that by myself .\n",
            "< i m doing this now of this this this this this this this this this this this this this this\n",
            "\n",
            "> прости что звоню так поздно .\n",
            "= i m sorry to call you so late at night .\n",
            "< i m sorry for i . <EOS>\n",
            "\n",
            "> ты странныи человек .\n",
            "= you re a strange man .\n",
            "< you are a man <EOS>\n",
            "\n",
            "> я убираюсь в своеи комнате .\n",
            "= i m cleaning my room .\n",
            "< i m going for are my <EOS>\n",
            "\n",
            "> они вероятно напуганы .\n",
            "= they re probably scared .\n",
            "< they re probably . <EOS>\n",
            "\n",
            "> вас невозможно забыть .\n",
            "= you re unforgettable .\n",
            "< you re going <EOS>\n",
            "\n",
            "> он энергичныи человек .\n",
            "= he is an active person .\n",
            "< he is a big a <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsq98naRfDid",
        "outputId": "eff2e7cd-0326-46e9-b368-f7d360af27c9"
      },
      "source": [
        "dec= ['mlp', 'scalar']*3\n",
        "dec"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp', 'scalar', 'mlp', 'scalar', 'mlp', 'scalar']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "suyUXNKidx8d",
        "outputId": "3e9bf7c8-f2aa-47c6-bb8a-73d1ad880ece"
      },
      "source": [
        "exp1 = pd.read_csv(PATH8+'Att1.csv').iloc[:,[1,2,4,5]]\n",
        "exp1['Decoder']   = dec\n",
        "exp1['learn_rate']= 0.05\n",
        "exp1 = exp1.iloc[:,[-1,0,1,2,3]]\n",
        "exp1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learn_rate</th>\n",
              "      <th>Max_length</th>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>Decoder</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>1.630128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>1.684131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>RNN</td>\n",
              "      <td>mlp</td>\n",
              "      <td>24.655075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>RNN</td>\n",
              "      <td>scalar</td>\n",
              "      <td>17.377365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>22.233171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.147843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   learn_rate  Max_length RNN_Type Decoder       Loss\n",
              "0        0.05          20     LSTM     mlp   1.630128\n",
              "1        0.05          20     LSTM  scalar   1.684131\n",
              "2        0.05          20      RNN     mlp  24.655075\n",
              "3        0.05          20      RNN  scalar  17.377365\n",
              "4        0.05          20      GRU     mlp  22.233171\n",
              "5        0.05          20      GRU  scalar   3.147843"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr3Mc4jA4HiB"
      },
      "source": [
        "#### 4.2.  Модель 2 - Предложения длиной от 3 до до 7 слов все / без привязки к шаблону / lr = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2Zr4vNGc6mt",
        "outputId": "0cf05a07-df0e-4df0-c756-364a3080b6b0"
      },
      "source": [
        "test_model_hw_8(max_length_sent = 7, prefix = None,\n",
        "                learn_rate = 0.05, teach_force_ratio = 0.5, \n",
        "                num_iters = 75000,  every = 5000, num_file ='Att2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 431097 sentence pairs\n",
            "Trimmed to 133723 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 27330\n",
            "eng 10085\n",
            "['он ходит быстро .', 'he walks fast .']\n",
            "\n",
            "Max_length =  7\n",
            "\n",
            "Decoder =  1\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 40s (- 23m 29s) (5000 6%) 4.0884\n",
            "3m 15s (- 21m 9s) (10000 13%) 3.4632\n",
            "4m 49s (- 19m 19s) (15000 20%) 3.1878\n",
            "6m 24s (- 17m 36s) (20000 26%) 2.9935\n",
            "7m 58s (- 15m 56s) (25000 33%) 2.9093\n",
            "9m 31s (- 14m 17s) (30000 40%) 2.7860\n",
            "11m 5s (- 12m 41s) (35000 46%) 2.7469\n",
            "12m 40s (- 11m 5s) (40000 53%) 2.6500\n",
            "14m 14s (- 9m 29s) (45000 60%) 2.5519\n",
            "15m 48s (- 7m 54s) (50000 66%) 2.5512\n",
            "17m 21s (- 6m 18s) (55000 73%) 2.5008\n",
            "18m 54s (- 4m 43s) (60000 80%) 2.4354\n",
            "20m 29s (- 3m 9s) (65000 86%) 2.3936\n",
            "22m 2s (- 1m 34s) (70000 93%) 2.3633\n",
            "23m 35s (- 0m 0s) (75000 100%) 2.3749\n",
            "\n",
            "evaluate\n",
            "\n",
            "> тому сегодня исполняется тринадцать лет .\n",
            "= tom turns thirteen today .\n",
            "< tom is a today . <EOS>\n",
            "\n",
            "> я знаю этого мальчика .\n",
            "= i know the boy .\n",
            "< i know this . . <EOS>\n",
            "\n",
            "> думаю это мое .\n",
            "= i think that s mine .\n",
            "< i think it ll mine . <EOS>\n",
            "\n",
            "> она сидела на скамеике .\n",
            "= she sat on the bench .\n",
            "< she did her the . . <EOS>\n",
            "\n",
            "> разве мы не счастливы вместе ?\n",
            "= aren t we happy together ?\n",
            "< can we we see together ? <EOS>\n",
            "\n",
            "> том набрал неправильныи номер .\n",
            "= tom dialed the wrong number .\n",
            "< tom is his wrong . <EOS>\n",
            "\n",
            "> вас зовут том верно ?\n",
            "= your name is tom right ?\n",
            "< is tom talking about tom ? <EOS>\n",
            "\n",
            "> спасибо за пиццу .\n",
            "= thanks for the pizza .\n",
            "< thanks for the thanks . <EOS>\n",
            "\n",
            "> ты не заидешь ?\n",
            "= aren t you coming inside ?\n",
            "< aren t you a ? <EOS>\n",
            "\n",
            "> не стои под дождем .\n",
            "= stay out of the rain .\n",
            "< don t look the . . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  7\n",
            "\n",
            "Decoder =  2\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 37s (- 22m 42s) (5000 6%) 4.0956\n",
            "3m 7s (- 20m 21s) (10000 13%) 3.4175\n",
            "4m 39s (- 18m 37s) (15000 20%) 3.1828\n",
            "6m 10s (- 16m 59s) (20000 26%) 3.0402\n",
            "7m 41s (- 15m 22s) (25000 33%) 2.8786\n",
            "9m 12s (- 13m 49s) (30000 40%) 2.7759\n",
            "10m 44s (- 12m 16s) (35000 46%) 2.7249\n",
            "12m 16s (- 10m 44s) (40000 53%) 2.6571\n",
            "13m 47s (- 9m 11s) (45000 60%) 2.5440\n",
            "15m 18s (- 7m 39s) (50000 66%) 2.5374\n",
            "16m 49s (- 6m 7s) (55000 73%) 2.4530\n",
            "18m 21s (- 4m 35s) (60000 80%) 2.4495\n",
            "19m 53s (- 3m 3s) (65000 86%) 2.4228\n",
            "21m 23s (- 1m 31s) (70000 93%) 2.3600\n",
            "22m 55s (- 0m 0s) (75000 100%) 2.3244\n",
            "\n",
            "evaluate\n",
            "\n",
            "> теперь у тома дети .\n",
            "= tom has children now .\n",
            "< now s s s now . <EOS>\n",
            "\n",
            "> тот малыш том .\n",
            "= that baby is tom .\n",
            "< it that tom tom tom <EOS>\n",
            "\n",
            "> том развелся с мэри .\n",
            "= tom divorced mary .\n",
            "< tom and mary with mary . <EOS>\n",
            "\n",
            "> мне надо его поблагодарить .\n",
            "= i have to thank him .\n",
            "< i need to do it . <EOS>\n",
            "\n",
            "> почему ты не плачешь ?\n",
            "= why don t you cry ?\n",
            "< why aren t you understand ? <EOS>\n",
            "\n",
            "> я в этом сомневаюсь .\n",
            "= i doubt that .\n",
            "< i m sure a . . <EOS>\n",
            "\n",
            "> у твоеи собаки плохои характер ?\n",
            "= is your dog mean ?\n",
            "< do my parents have ? ? <EOS>\n",
            "\n",
            "> я забираю все назад .\n",
            "= i take everything back .\n",
            "< i ve all your . . <EOS>\n",
            "\n",
            "> не делаи этого !\n",
            "= don t do it .\n",
            "< don t do it . <EOS>\n",
            "\n",
            "> могу я вам помочь господа ?\n",
            "= can i help you gentlemen ?\n",
            "< may i help you ? ? <EOS>\n",
            "\n",
            "\n",
            "Max_length =  7\n",
            "\n",
            "Decoder =  1\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 37s (- 22m 44s) (5000 6%) 3.9507\n",
            "3m 10s (- 20m 38s) (10000 13%) 3.5585\n",
            "4m 42s (- 18m 48s) (15000 20%) 3.8965\n",
            "6m 9s (- 16m 56s) (20000 26%) 11.5439\n",
            "7m 36s (- 15m 12s) (25000 33%) 19.4090\n",
            "9m 4s (- 13m 36s) (30000 40%) 19.1907\n",
            "10m 30s (- 12m 1s) (35000 46%) 18.7808\n",
            "11m 57s (- 10m 28s) (40000 53%) 19.7023\n",
            "13m 26s (- 8m 57s) (45000 60%) 19.6229\n",
            "14m 54s (- 7m 27s) (50000 66%) 19.7204\n",
            "16m 22s (- 5m 57s) (55000 73%) 19.7103\n",
            "17m 50s (- 4m 27s) (60000 80%) 19.4103\n",
            "19m 18s (- 2m 58s) (65000 86%) 20.0643\n",
            "20m 46s (- 1m 29s) (70000 93%) 19.7280\n",
            "22m 13s (- 0m 0s) (75000 100%) 19.4450\n",
            "\n",
            "evaluate\n",
            "\n",
            "> мы его починим .\n",
            "= we ll fix it .\n",
            "< stay stay stay stay stay stay stay\n",
            "\n",
            "> том тебе меня слышно ?\n",
            "= tom can you hear me ?\n",
            "< may today interrupting ? interrupting ? interrupting\n",
            "\n",
            "> может так и есть .\n",
            "= maybe it s like that .\n",
            "< tom tom tom tom tom tom tom\n",
            "\n",
            "> я поиграю с тобои .\n",
            "= i ll play with you .\n",
            "< stay stay stay stay stay stay stay\n",
            "\n",
            "> я перешла через улицу .\n",
            "= i crossed the street .\n",
            "< stay . stay . stay . stay\n",
            "\n",
            "> я на дежурстве .\n",
            "= i m on duty .\n",
            "< tom stay . . . . .\n",
            "\n",
            "> небо было голубое .\n",
            "= the sky was blue .\n",
            "< calm . calm . calm . calm\n",
            "\n",
            "> не теряи самообладания .\n",
            "= don t lose your cool .\n",
            "< tom stay . . . . .\n",
            "\n",
            "> том мои старшии брат .\n",
            "= tom is my older brother .\n",
            "< tom stay . . . . .\n",
            "\n",
            "> он оставил двигатель включенным .\n",
            "= he left the motor running .\n",
            "< tom stay . . . . .\n",
            "\n",
            "\n",
            "Max_length =  7\n",
            "\n",
            "Decoder =  2\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 34s (- 22m 8s) (5000 6%) 4.0138\n",
            "3m 5s (- 20m 7s) (10000 13%) 3.7943\n",
            "4m 34s (- 18m 17s) (15000 20%) 5.3477\n",
            "5m 59s (- 16m 28s) (20000 26%) 10.9732\n",
            "7m 25s (- 14m 51s) (25000 33%) 14.0146\n",
            "8m 50s (- 13m 15s) (30000 40%) 14.4271\n",
            "10m 15s (- 11m 43s) (35000 46%) 15.0154\n",
            "11m 41s (- 10m 14s) (40000 53%) 15.7534\n",
            "13m 8s (- 8m 45s) (45000 60%) 16.4504\n",
            "14m 34s (- 7m 17s) (50000 66%) 16.8257\n",
            "15m 58s (- 5m 48s) (55000 73%) 16.5674\n",
            "17m 23s (- 4m 20s) (60000 80%) 16.2299\n",
            "18m 49s (- 2m 53s) (65000 86%) 16.2628\n",
            "20m 14s (- 1m 26s) (70000 93%) 15.7460\n",
            "21m 39s (- 0m 0s) (75000 100%) 15.1908\n",
            "\n",
            "evaluate\n",
            "\n",
            "> я бегаю по утрам .\n",
            "= i jog every morning .\n",
            "< i am this won won won won\n",
            "\n",
            "> понедельник не подходит .\n",
            "= monday s not good .\n",
            "< i like won a t were t\n",
            "\n",
            "> беги и прячься .\n",
            "= run and hide .\n",
            "< this we life liars this very life\n",
            "\n",
            "> можно мне с томом поехать ?\n",
            "= may i go with tom ?\n",
            "< did are this are this are this\n",
            "\n",
            "> вы хорошо себя сегодня вели ?\n",
            "= did you behave today ?\n",
            "< did are did are did are did\n",
            "\n",
            "> как ты это сделала ?\n",
            "= how did you do that ?\n",
            "< this did this did this this did\n",
            "\n",
            "> кто нибудь что нибудь сказал ?\n",
            "= did anyone say anything ?\n",
            "< did did did did did did did\n",
            "\n",
            "> ты слышал что я сказала .\n",
            "= you heard what i said .\n",
            "< i am were am me were am\n",
            "\n",
            "> она сестра тома .\n",
            "= she s tom s sister .\n",
            "< we life very life liars this very\n",
            "\n",
            "> вы еще хотите чаю ?\n",
            "= do you still want tea ?\n",
            "< did are this are this are this\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "r7JDrfj7dNqL",
        "outputId": "bf358812-f390-475b-cbc6-de500c81b906"
      },
      "source": [
        "exp2 = pd.read_csv(PATH8+'Att2.csv').iloc[:,[1,2,4,5]]\n",
        "exp2['Decoder'] = dec[:4]\n",
        "exp2['learn_rate']= 0.05\n",
        "exp2 = exp2.iloc[:,[-1,0,1,2,3]]\n",
        "exp2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learn_rate</th>\n",
              "      <th>Max_length</th>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>Decoder</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>7</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>2.374869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>7</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>2.324447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.05</td>\n",
              "      <td>7</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>19.445005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.05</td>\n",
              "      <td>7</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>15.190802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   learn_rate  Max_length RNN_Type Decoder       Loss\n",
              "0        0.05           7     LSTM     mlp   2.374869\n",
              "1        0.05           7     LSTM  scalar   2.324447\n",
              "2        0.05           7      GRU     mlp  19.445005\n",
              "3        0.05           7      GRU  scalar  15.190802"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DnJ3ENEdSj1"
      },
      "source": [
        "#### 4.3.  Модель 3 - Предложения длиной от 3 до 20 слов все / без привязки к шаблону  / lr = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtEBhMRxgQd7",
        "outputId": "9f3be542-90c0-4501-cc34-4a50d9b5cba7"
      },
      "source": [
        "test_model_hw_8(max_length_sent = 20, prefix = None,\n",
        "                learn_rate = 0.05, teach_force_ratio = 0.5, \n",
        "                num_iters = 75000,  every = 5000, num_file ='Att3')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 431097 sentence pairs\n",
            "Trimmed to 409735 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 52630\n",
            "eng 15912\n",
            "['могу я там быть ?', 'can i be there ?']\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "LSTM\n",
            "\n",
            "training\n",
            "2m 7s (- 29m 46s) (5000 6%) 4.3734\n",
            "4m 12s (- 27m 24s) (10000 13%) 3.8669\n",
            "6m 16s (- 25m 5s) (15000 20%) 3.6197\n",
            "8m 20s (- 22m 55s) (20000 26%) 3.5030\n",
            "10m 24s (- 20m 48s) (25000 33%) 3.4144\n",
            "12m 28s (- 18m 42s) (30000 40%) 3.3235\n",
            "14m 31s (- 16m 35s) (35000 46%) 3.3028\n",
            "16m 36s (- 14m 31s) (40000 53%) 3.1999\n",
            "18m 40s (- 12m 26s) (45000 60%) 3.1689\n",
            "20m 44s (- 10m 22s) (50000 66%) 3.1132\n",
            "22m 50s (- 8m 18s) (55000 73%) 3.1159\n",
            "24m 54s (- 6m 13s) (60000 80%) 3.0528\n",
            "26m 58s (- 4m 9s) (65000 86%) 3.0477\n",
            "29m 2s (- 2m 4s) (70000 93%) 3.0122\n",
            "31m 7s (- 0m 0s) (75000 100%) 2.9940\n",
            "\n",
            "evaluate\n",
            "\n",
            "> вы похоже довольно хорошо знаете тома .\n",
            "= you seem to know tom pretty well .\n",
            "< you seem to s tom tom tom . <EOS>\n",
            "\n",
            "> тебе не стоило так беспокоиться .\n",
            "= you shouldn t have worried so much .\n",
            "< you don t need to . . <EOS>\n",
            "\n",
            "> звучит не так уж плохо .\n",
            "= it doesn t sound too bad .\n",
            "< that s don t t . . . <EOS>\n",
            "\n",
            "> в детстве я был очень полным .\n",
            "= i was very chubby when i was a child .\n",
            "< i was very happy i was . <EOS>\n",
            "\n",
            "> том выглядит сонным .\n",
            "= tom looks drowsy .\n",
            "< tom is a . . <EOS>\n",
            "\n",
            "> мне нужен кто нибудь кто заслуживает доверия .\n",
            "= i need someone who s trustworthy .\n",
            "< i need going to tell anyone . <EOS>\n",
            "\n",
            "> я могу помочь тому это сделать .\n",
            "= i can help tom do that .\n",
            "< i can do do to . <EOS>\n",
            "\n",
            "> вы меня больше не увидите .\n",
            "= you won t see me anymore .\n",
            "< you don t t me anymore anymore . <EOS>\n",
            "\n",
            "> я не хочу прикидываться тем кем не являюсь .\n",
            "= i don t want to pretend i m someone i m not .\n",
            "< i don t want to to the . . . . . <EOS>\n",
            "\n",
            "> не спрашиваи пожалуиста .\n",
            "= please don t ask .\n",
            "< please don t please . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "LSTM\n",
            "\n",
            "training\n",
            "2m 4s (- 29m 1s) (5000 6%) 4.3298\n",
            "4m 4s (- 26m 29s) (10000 13%) 3.8145\n",
            "6m 3s (- 24m 15s) (15000 20%) 3.6486\n",
            "8m 3s (- 22m 10s) (20000 26%) 3.5230\n",
            "10m 4s (- 20m 9s) (25000 33%) 3.4206\n",
            "12m 5s (- 18m 8s) (30000 40%) 3.3571\n",
            "14m 7s (- 16m 8s) (35000 46%) 3.3012\n",
            "16m 9s (- 14m 8s) (40000 53%) 3.2613\n",
            "18m 11s (- 12m 7s) (45000 60%) 3.2511\n",
            "20m 13s (- 10m 6s) (50000 66%) 3.1837\n",
            "22m 13s (- 8m 5s) (55000 73%) 3.1636\n",
            "24m 16s (- 6m 4s) (60000 80%) 3.1271\n",
            "26m 16s (- 4m 2s) (65000 86%) 3.0798\n",
            "28m 17s (- 2m 1s) (70000 93%) 3.0622\n",
            "30m 18s (- 0m 0s) (75000 100%) 3.0254\n",
            "\n",
            "evaluate\n",
            "\n",
            "> том знал что мэри не даст ему себя поцеловать .\n",
            "= tom knew mary wouldn t let him kiss her .\n",
            "< tom knew he was was in . . . <EOS>\n",
            "\n",
            "> все мои бывшие девушки живут в бостоне .\n",
            "= all my ex girlfriends live in boston .\n",
            "< everyone went back in the the . <EOS>\n",
            "\n",
            "> кто ходил с вами на рыбалку ?\n",
            "= who went fishing with you ?\n",
            "< who is you with you ? <EOS>\n",
            "\n",
            "> том скорее всего занят .\n",
            "= tom is likely to be busy .\n",
            "< tom was be busy of the <EOS>\n",
            "\n",
            "> я хочу посмотреть как вы танцуете .\n",
            "= i want to watch you dance .\n",
            "< i want to know how you you . <EOS>\n",
            "\n",
            "> том сегодня утром тебя искал .\n",
            "= tom was looking for you this morning .\n",
            "< tom is be to . . . <EOS>\n",
            "\n",
            "> я не хочу раскачивать лодку .\n",
            "= i don t want to rock the boat .\n",
            "< i don t want to go . . <EOS>\n",
            "\n",
            "> куда я ее подевал ?\n",
            "= where did i put it ?\n",
            "< where did your your <EOS>\n",
            "\n",
            "> я о тебе почти ничего не знаю .\n",
            "= i know almost nothing about you .\n",
            "< i want what happened . know . <EOS>\n",
            "\n",
            "> ты хочешь чтобы я сделал это с тобои ?\n",
            "= do you want me to do that with you ?\n",
            "< do you want to to do with him ? <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "GRU\n",
            "\n",
            "training\n",
            "2m 4s (- 29m 6s) (5000 6%) 4.3401\n",
            "4m 4s (- 26m 29s) (10000 13%) 3.9725\n",
            "6m 5s (- 24m 21s) (15000 20%) 3.9857\n",
            "8m 6s (- 22m 17s) (20000 26%) 3.9195\n",
            "10m 4s (- 20m 9s) (25000 33%) 3.8344\n",
            "12m 4s (- 18m 6s) (30000 40%) 13.0092\n",
            "14m 3s (- 16m 4s) (35000 46%) 18.4980\n",
            "16m 2s (- 14m 2s) (40000 53%) 20.7948\n",
            "18m 3s (- 12m 2s) (45000 60%) 21.5640\n",
            "20m 2s (- 10m 1s) (50000 66%) 21.0614\n",
            "22m 3s (- 8m 1s) (55000 73%) 22.5869\n",
            "24m 3s (- 6m 0s) (60000 80%) 22.2647\n",
            "26m 4s (- 4m 0s) (65000 86%) 23.1818\n",
            "28m 3s (- 2m 0s) (70000 93%) 23.4375\n",
            "30m 2s (- 0m 0s) (75000 100%) 24.0581\n",
            "\n",
            "evaluate\n",
            "\n",
            "> что это вы делаете ?\n",
            "= what is it you do ?\n",
            "< why did <EOS>\n",
            "\n",
            "> ты наидешь это .\n",
            "= you ll find it .\n",
            "< tom <EOS>\n",
            "\n",
            "> том еще не получил свои водительские права .\n",
            "= tom hasn t gotten his driver s license yet .\n",
            "< tom <EOS>\n",
            "\n",
            "> том талантливыи пианист .\n",
            "= tom is a gifted pianist .\n",
            "< tom <EOS>\n",
            "\n",
            "> на кухне чисто .\n",
            "= the kitchen is clean .\n",
            "< tom <EOS>\n",
            "\n",
            "> я не думаю что том неудачник .\n",
            "= i don t think tom is a loser .\n",
            "< tom <EOS>\n",
            "\n",
            "> почему ты не обращаешь на меня внимания ?\n",
            "= why are you ignoring me ?\n",
            "< why could <EOS>\n",
            "\n",
            "> кто нибудь об этом помнит ?\n",
            "= does someone remember it ?\n",
            "< open the <EOS>\n",
            "\n",
            "> можешь налить мне еще вина ?\n",
            "= can you please pour me some more wine ?\n",
            "< why wrote in here <EOS>\n",
            "\n",
            "> том сидит в машине рядом с мэри .\n",
            "= tom is sitting in the car beside mary .\n",
            "< tom <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "GRU\n",
            "\n",
            "training\n",
            "2m 1s (- 28m 27s) (5000 6%) 4.4034\n",
            "3m 56s (- 25m 36s) (10000 13%) 5.3853\n",
            "5m 52s (- 23m 28s) (15000 20%) 14.5237\n",
            "7m 48s (- 21m 27s) (20000 26%) 23.2623\n",
            "9m 44s (- 19m 29s) (25000 33%) 26.1692\n",
            "11m 40s (- 17m 30s) (30000 40%) 25.6672\n",
            "13m 35s (- 15m 32s) (35000 46%) 25.2602\n",
            "15m 32s (- 13m 35s) (40000 53%) 25.9930\n",
            "17m 27s (- 11m 38s) (45000 60%) 27.4698\n",
            "19m 24s (- 9m 42s) (50000 66%) 26.4261\n",
            "21m 19s (- 7m 45s) (55000 73%) 26.9714\n",
            "23m 14s (- 5m 48s) (60000 80%) 26.9533\n",
            "25m 9s (- 3m 52s) (65000 86%) 28.0576\n",
            "27m 4s (- 1m 56s) (70000 93%) 28.4507\n",
            "29m 0s (- 0m 0s) (75000 100%) 28.0917\n",
            "\n",
            "evaluate\n",
            "\n",
            "> когда ты закончил школу ?\n",
            "= when did you graduate from high school ?\n",
            "< do real do real real real real do real real real real real real real real real real do real\n",
            "\n",
            "> он терпеть не может ходить по магазинам .\n",
            "= he hates shopping .\n",
            "< i knew knew knew knew i knew knew knew knew i knew knew knew knew knew knew knew knew knew\n",
            "\n",
            "> что это за цветок ?\n",
            "= what s that flower ?\n",
            "< do do do do do do do do do do do do do do do do do do do do\n",
            "\n",
            "> попроси у него совета .\n",
            "= ask him for advice .\n",
            "< i knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew\n",
            "\n",
            "> тебе нравятся книги написанные францем кафкои ?\n",
            "= do you like books written by franz kafka ?\n",
            "< tom tom tom tom tom tom tom tom tom tom tom tom tom tom tom tom tom tom tom tom\n",
            "\n",
            "> я не люблю такие шутки .\n",
            "= i don t like this kind of joke .\n",
            "< tom knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew knew\n",
            "\n",
            "> извини не думаю что смогу это сделать .\n",
            "= sorry i don t think i can do that .\n",
            "< i i i i i i i i i i i i i i i i i i i i\n",
            "\n",
            "> у тома есть деньги ?\n",
            "= does tom have money ?\n",
            "< i ? doing real doing real doing real doing real doing real doing real doing real doing real doing real\n",
            "\n",
            "> я этого заслуживаю ?\n",
            "= do i deserve this ?\n",
            "< do do do do do do do do do do do do do do do do do do do do\n",
            "\n",
            "> оно белое как снег .\n",
            "= it is white as snow .\n",
            "< i no re no re no re no re no re no re no re no re no no re\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "b3_Oq_0ydNw6",
        "outputId": "c6774419-bae7-450d-996d-bb4b253da03c"
      },
      "source": [
        "exp3 = pd.read_csv(PATH8+'Att3.csv').iloc[:,[1,2,4,5]]\n",
        "exp3['Decoder']   = dec[:4]\n",
        "exp3['learn_rate']= 0.05\n",
        "exp3              = exp3.iloc[:,[-1,0,1,2,3]]\n",
        "exp3"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learn_rate</th>\n",
              "      <th>Max_length</th>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>Decoder</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>2.994014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>24.058059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>28.091668</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   learn_rate  Max_length RNN_Type Decoder       Loss\n",
              "0        0.05          20     LSTM     mlp   2.994014\n",
              "1        0.05          20     LSTM  scalar   3.025424\n",
              "2        0.05          20      GRU     mlp  24.058059\n",
              "3        0.05          20      GRU  scalar  28.091668"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOMEOxbrc6mw"
      },
      "source": [
        "#### 4.4.  Модель 4 - Предложения длиной от 3 до 20 слов все / без привязки к шаблону / lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEza6nGugs6Y",
        "outputId": "089ad64c-2fa7-4143-82fc-62783083b0d0"
      },
      "source": [
        "test_model_hw_8(max_length_sent = 20, prefix = None,\n",
        "                learn_rate = 0.001, teach_force_ratio = 0.5, \n",
        "                num_iters = 75000,  every = 5000, num_file ='Att5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 431097 sentence pairs\n",
            "Trimmed to 409735 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 52630\n",
            "eng 15912\n",
            "['том перевел дух .', 'tom caught his breath .']\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 57s (- 27m 19s) (5000 6%) 5.1609\n",
            "3m 55s (- 25m 27s) (10000 13%) 4.5757\n",
            "5m 55s (- 23m 43s) (15000 20%) 4.4462\n",
            "7m 57s (- 21m 53s) (20000 26%) 4.4086\n",
            "10m 2s (- 20m 4s) (25000 33%) 4.3574\n",
            "12m 8s (- 18m 12s) (30000 40%) 4.2794\n",
            "14m 12s (- 16m 14s) (35000 46%) 4.2393\n",
            "16m 17s (- 14m 15s) (40000 53%) 4.1993\n",
            "18m 22s (- 12m 14s) (45000 60%) 4.1271\n",
            "20m 27s (- 10m 13s) (50000 66%) 4.0320\n",
            "22m 33s (- 8m 12s) (55000 73%) 3.9673\n",
            "24m 37s (- 6m 9s) (60000 80%) 3.9405\n",
            "26m 42s (- 4m 6s) (65000 86%) 3.8821\n",
            "28m 46s (- 2m 3s) (70000 93%) 3.9011\n",
            "30m 50s (- 0m 0s) (75000 100%) 3.8348\n",
            "\n",
            "evaluate\n",
            "\n",
            "> я не хочу видеть твое лицо снова .\n",
            "= i don t want to see your face again .\n",
            "< i don t know to to to . . <EOS>\n",
            "\n",
            "> вам не понравится то что я сеичас скажу .\n",
            "= you won t like what i m going to say .\n",
            "< i don t know what you do that . <EOS>\n",
            "\n",
            "> сядьте поговорите со мнои .\n",
            "= sit down and talk with me .\n",
            "< the is is the . . <EOS>\n",
            "\n",
            "> том что опять это сделал ?\n",
            "= tom did that again didn t he ?\n",
            "< what tom tom tom do that ? <EOS>\n",
            "\n",
            "> том хочет чтобы ты вернулся домои .\n",
            "= tom wants you to come home .\n",
            "< tom is the to to . . . <EOS>\n",
            "\n",
            "> вы не видели за ужином тома ?\n",
            "= didn t you see tom at dinner ?\n",
            "< why t you tom tom tom ? <EOS>\n",
            "\n",
            "> мы возвращаемся в австралию двадцатого октября .\n",
            "= we return to australia on october th .\n",
            "< the is is in the . . <EOS>\n",
            "\n",
            "> можете говорить что хотите .\n",
            "= you can say whatever you want .\n",
            "< we re not to . . <EOS>\n",
            "\n",
            "> она училась в бельгии .\n",
            "= she studied in belgium .\n",
            "< the is is the . . <EOS>\n",
            "\n",
            "> я хочу открыть собственныи ресторан .\n",
            "= i want to open a restaurant of my own .\n",
            "< i m to to to . . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 51s (- 26m 1s) (5000 6%) 5.1168\n",
            "3m 42s (- 24m 9s) (10000 13%) 4.5934\n",
            "5m 35s (- 22m 22s) (15000 20%) 4.4227\n",
            "7m 27s (- 20m 29s) (20000 26%) 4.3351\n",
            "9m 19s (- 18m 39s) (25000 33%) 4.2785\n",
            "11m 14s (- 16m 52s) (30000 40%) 4.2030\n",
            "13m 9s (- 15m 2s) (35000 46%) 4.1293\n",
            "15m 4s (- 13m 11s) (40000 53%) 4.0764\n",
            "17m 0s (- 11m 20s) (45000 60%) 4.0445\n",
            "18m 56s (- 9m 28s) (50000 66%) 4.0238\n",
            "20m 52s (- 7m 35s) (55000 73%) 3.9756\n",
            "22m 49s (- 5m 42s) (60000 80%) 3.9460\n",
            "24m 46s (- 3m 48s) (65000 86%) 3.9119\n",
            "26m 45s (- 1m 54s) (70000 93%) 3.8792\n",
            "28m 43s (- 0m 0s) (75000 100%) 3.8132\n",
            "\n",
            "evaluate\n",
            "\n",
            "> все имеют право изредка быть в плохом настроении .\n",
            "= everyone is entitled to be moody once in a while .\n",
            "< we re to to to . . . . <EOS>\n",
            "\n",
            "> он читает книгу .\n",
            "= he is reading a book .\n",
            "< he is a . . . . <EOS>\n",
            "\n",
            "> почему ты просто не скажешь тому что совершил ошибку ?\n",
            "= why don t you just tell tom you made a mistake ?\n",
            "< why did you know tom tom tom tom ? ? ? <EOS>\n",
            "\n",
            "> между двумя рядами домов проходил канал .\n",
            "= a canal flowed between two rows of houses .\n",
            "< we re to to . . . . <EOS>\n",
            "\n",
            "> том не разрешит нам поити .\n",
            "= tom won t let us go .\n",
            "< tom didn t know to . . . <EOS>\n",
            "\n",
            "> я жду вашего ответа .\n",
            "= i m waiting for your answer .\n",
            "< i m a . . . <EOS>\n",
            "\n",
            "> я должен сказать тебе правду .\n",
            "= i have to tell you the truth .\n",
            "< i m you you . . . <EOS>\n",
            "\n",
            "> они отгородили участок для стоянки автомобилеи .\n",
            "= they fenced off an area to park cars .\n",
            "< he is a to . . . . <EOS>\n",
            "\n",
            ">  отличных выходных ! тебе тоже ! \n",
            "=  have a great weekend ! same to you ! \n",
            "< you re to to to to . . . <EOS>\n",
            "\n",
            "> я не останусь здесь один .\n",
            "= i won t stay here alone .\n",
            "< i don t have to . . . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 56s (- 27m 16s) (5000 6%) 4.9001\n",
            "3m 54s (- 25m 26s) (10000 13%) 4.5896\n",
            "5m 56s (- 23m 44s) (15000 20%) 4.4246\n",
            "7m 55s (- 21m 46s) (20000 26%) 4.3282\n",
            "9m 52s (- 19m 45s) (25000 33%) 4.2131\n",
            "11m 51s (- 17m 46s) (30000 40%) 4.1237\n",
            "13m 48s (- 15m 47s) (35000 46%) 4.0157\n",
            "15m 45s (- 13m 47s) (40000 53%) 3.9195\n",
            "17m 44s (- 11m 49s) (45000 60%) 3.8369\n",
            "19m 40s (- 9m 50s) (50000 66%) 3.8039\n",
            "21m 40s (- 7m 52s) (55000 73%) 3.7572\n",
            "23m 40s (- 5m 55s) (60000 80%) 3.7150\n",
            "25m 41s (- 3m 57s) (65000 86%) 3.6819\n",
            "27m 40s (- 1m 58s) (70000 93%) 3.6178\n",
            "29m 40s (- 0m 0s) (75000 100%) 3.6004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "evaluate\n",
            "\n",
            "> вы можете меня защитить .\n",
            "= you can protect me .\n",
            "< you re me . . <EOS>\n",
            "\n",
            "> том перевел пожилую женщину через дорогу .\n",
            "= tom helped an old woman cross the street .\n",
            "< tom is a to to the . . . <EOS>\n",
            "\n",
            "> мы должны поговорить .\n",
            "= we must talk .\n",
            "< we re a . . <EOS>\n",
            "\n",
            "> том сел на корточки .\n",
            "= tom squatted down .\n",
            "< tom is to to . . <EOS>\n",
            "\n",
            "> сколько солдат вы видели ?\n",
            "= how many soldiers did you see ?\n",
            "< how do you you to ? ? <EOS>\n",
            "\n",
            "> я рад что вы это оценили .\n",
            "= i m glad you appreciated that .\n",
            "< i thought that you re do that . <EOS>\n",
            "\n",
            "> мне надо было увидеть вас лично .\n",
            "= i needed to see you in person .\n",
            "< i think you you you you . . <EOS>\n",
            "\n",
            "> мы живем рядом со станциеи .\n",
            "= we live close to the station .\n",
            "< we re to to . . . <EOS>\n",
            "\n",
            "> он сдержал обещание .\n",
            "= he kept his promise .\n",
            "< he is a . . <EOS>\n",
            "\n",
            "> хочешь в прятки сыграть ?\n",
            "= do you want to play hide and seek ?\n",
            "< do you have to ? ? ? <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 51s (- 26m 3s) (5000 6%) 4.9108\n",
            "3m 42s (- 24m 5s) (10000 13%) 4.4560\n",
            "5m 31s (- 22m 5s) (15000 20%) 4.3170\n",
            "7m 22s (- 20m 18s) (20000 26%) 4.2753\n",
            "9m 14s (- 18m 28s) (25000 33%) 4.2407\n",
            "11m 6s (- 16m 39s) (30000 40%) 4.1536\n",
            "12m 59s (- 14m 50s) (35000 46%) 4.1063\n",
            "14m 52s (- 13m 1s) (40000 53%) 4.0196\n",
            "16m 46s (- 11m 10s) (45000 60%) 4.0153\n",
            "18m 38s (- 9m 19s) (50000 66%) 3.9475\n",
            "20m 30s (- 7m 27s) (55000 73%) 3.9048\n",
            "22m 24s (- 5m 36s) (60000 80%) 3.8391\n",
            "24m 18s (- 3m 44s) (65000 86%) 3.8187\n",
            "26m 13s (- 1m 52s) (70000 93%) 3.8141\n",
            "28m 8s (- 0m 0s) (75000 100%) 3.7391\n",
            "\n",
            "evaluate\n",
            "\n",
            "> еи не может быть больше тридцати .\n",
            "= she cannot be over thirty .\n",
            "< don t have to to . . <EOS>\n",
            "\n",
            "> я планирую покататься на лыжах на хоккаидо .\n",
            "= i plan to go skiing in hokkaido .\n",
            "< i ve got to to the . . <EOS>\n",
            "\n",
            "> я играю на органе .\n",
            "= i play the organ .\n",
            "< i m a . . <EOS>\n",
            "\n",
            "> не обращаи внимания на ее капризы .\n",
            "= don t pay any attention to her whims .\n",
            "< don t t to . . <EOS>\n",
            "\n",
            "> том тебя ищет .\n",
            "= tom s been looking for you .\n",
            "< tom said that he was . <EOS>\n",
            "\n",
            "> тебе надо идти спать .\n",
            "= you have to go to sleep .\n",
            "< you re to to . . <EOS>\n",
            "\n",
            "> я еще молодая .\n",
            "= i m still young .\n",
            "< i m a . . <EOS>\n",
            "\n",
            "> он раньше ездил в школу на велосипеде а теперь на автобусе .\n",
            "= he used to go to school by bicycle but now he goes by bus .\n",
            "< he was the to to the the in the the . <EOS>\n",
            "\n",
            "> не пеи слишком много ладно ?\n",
            "= don t drink too much okay ?\n",
            "< don t you to to ? ? <EOS>\n",
            "\n",
            "> тому нужна помощь ?\n",
            "= does tom need a hand ?\n",
            "< what tom tom tom ? <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "wUhk_qLYdN3g",
        "outputId": "8bc3f843-4bae-43b6-8f96-aab602a15c8a"
      },
      "source": [
        "exp4                = pd.read_csv(PATH8+'Att5.csv').iloc[:,[1,2,4,5]]\n",
        "exp4['Decoder']     = dec[:4]\n",
        "exp4['learn_rate']  = 0.001\n",
        "exp4                = exp4.iloc[:,[-1,0,1,2,3]]\n",
        "exp4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learn_rate</th>\n",
              "      <th>Max_length</th>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>Decoder</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.834810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.813181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.600392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.739083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   learn_rate  Max_length RNN_Type Decoder      Loss\n",
              "0       0.001          20     LSTM     mlp  3.834810\n",
              "1       0.001          20     LSTM  scalar  3.813181\n",
              "2       0.001          20      GRU     mlp  3.600392\n",
              "3       0.001          20      GRU  scalar  3.739083"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX_Y5mzghpgM"
      },
      "source": [
        "#### 4.5.  Модель 5 - Предложения длиной от 3 до 20 слов все / без привязки к шаблону / lr = 0.003"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAvj-F-GiBat",
        "outputId": "816b749e-7590-4e23-c235-107732cdb6d9"
      },
      "source": [
        "test_model_hw_8(max_length_sent = 20, prefix = None,\n",
        "                learn_rate = 0.003, teach_force_ratio = 0.5, \n",
        "                num_iters = 75000,  every = 5000, num_file ='Att6')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 431097 sentence pairs\n",
            "Trimmed to 409735 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 52630\n",
            "eng 15912\n",
            "['я никогда не убираю постель .', 'i never make my bed .']\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 23s (- 19m 28s) (5000 6%) 4.7282\n",
            "2m 46s (- 18m 3s) (10000 13%) 4.3429\n",
            "4m 11s (- 16m 44s) (15000 20%) 4.2268\n",
            "5m 36s (- 15m 25s) (20000 26%) 4.0934\n",
            "7m 2s (- 14m 5s) (25000 33%) 4.0071\n",
            "8m 28s (- 12m 42s) (30000 40%) 3.8652\n",
            "9m 53s (- 11m 18s) (35000 46%) 3.7824\n",
            "11m 19s (- 9m 54s) (40000 53%) 3.7216\n",
            "12m 46s (- 8m 30s) (45000 60%) 3.6613\n",
            "14m 12s (- 7m 6s) (50000 66%) 3.5384\n",
            "15m 38s (- 5m 41s) (55000 73%) 3.5056\n",
            "17m 5s (- 4m 16s) (60000 80%) 3.4432\n",
            "18m 32s (- 2m 51s) (65000 86%) 3.3928\n",
            "19m 58s (- 1m 25s) (70000 93%) 3.3201\n",
            "21m 24s (- 0m 0s) (75000 100%) 3.2659\n",
            "\n",
            "evaluate\n",
            "\n",
            "> он сказал что поможет мне .\n",
            "= he said that he would help me .\n",
            "< he told me to me to . <EOS>\n",
            "\n",
            "> хочу себе друга по переписке .\n",
            "= i want a pen pal .\n",
            "< i want to go to . . <EOS>\n",
            "\n",
            "> есть слабая надежда что они живы .\n",
            "= there is little hope that they are alive .\n",
            "< they are still have a lot of . <EOS>\n",
            "\n",
            "> этот код нельзя взломать .\n",
            "= the code cannot be cracked .\n",
            "< this s not to . . <EOS>\n",
            "\n",
            "> я начал здесь работать в прошлыи понедельник .\n",
            "= i started working here last monday .\n",
            "< i ve got to go to boston in . <EOS>\n",
            "\n",
            "> она гораздо счастливее его .\n",
            "= she s much happier than him .\n",
            "< she is a the . . <EOS>\n",
            "\n",
            "> смотри там кролик !\n",
            "= look there s a rabbit !\n",
            "< what s a <EOS>\n",
            "\n",
            "> он отошел в сторону позволив старику проити .\n",
            "= he stepped aside for an old man to pass .\n",
            "< he is a to in in in <EOS>\n",
            "\n",
            "> я расследую одно очень интересное дело .\n",
            "= i m investigating a very interesting case .\n",
            "< i ve got to a very . . <EOS>\n",
            "\n",
            "> это та книга которую тебе том дал ?\n",
            "= is that the book that tom gave you ?\n",
            "< how did you think that tom is that ? ? <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 23s (- 19m 28s) (5000 6%) 4.7743\n",
            "2m 44s (- 17m 50s) (10000 13%) 4.2904\n",
            "4m 7s (- 16m 28s) (15000 20%) 4.1369\n",
            "5m 31s (- 15m 11s) (20000 26%) 4.0353\n",
            "6m 55s (- 13m 51s) (25000 33%) 3.9562\n",
            "8m 19s (- 12m 29s) (30000 40%) 3.8450\n",
            "9m 44s (- 11m 8s) (35000 46%) 3.7996\n",
            "11m 9s (- 9m 45s) (40000 53%) 3.6895\n",
            "12m 34s (- 8m 22s) (45000 60%) 3.6459\n",
            "13m 58s (- 6m 59s) (50000 66%) 3.5607\n",
            "15m 22s (- 5m 35s) (55000 73%) 3.4885\n",
            "16m 47s (- 4m 11s) (60000 80%) 3.4426\n",
            "18m 11s (- 2m 47s) (65000 86%) 3.4058\n",
            "19m 36s (- 1m 24s) (70000 93%) 3.3667\n",
            "21m 1s (- 0m 0s) (75000 100%) 3.2804\n",
            "\n",
            "evaluate\n",
            "\n",
            "> он попросил меня помочь ему .\n",
            "= he asked me to help him .\n",
            "< he asked me to me . <EOS>\n",
            "\n",
            "> заседание суда продолжалось с восьми часов утра до пяти часов вечера .\n",
            "= the court was in session from eight in the morning to five in the afternoon .\n",
            "< the one of the i and i a a a a . . . . <EOS>\n",
            "\n",
            "> ты же меня здесь подождешь ?\n",
            "= you re going to wait here for me aren t you ?\n",
            "< do you think i m here ? <EOS>\n",
            "\n",
            "> том решил поити другим путем .\n",
            "= tom decided to go a different way .\n",
            "< tom is to to to . . . <EOS>\n",
            "\n",
            "> у тома это лучше получается чем у меня .\n",
            "= tom is better at doing that than me .\n",
            "< tom has a as as as i as i . <EOS>\n",
            "\n",
            "> ты знаком с моим мужем ?\n",
            "= do you know my husband ?\n",
            "< do you like a a ? ? ? <EOS>\n",
            "\n",
            "> том научил меня свистеть .\n",
            "= tom taught me how to whistle .\n",
            "< tom is me me . . <EOS>\n",
            "\n",
            "> зачем ты его сюда положил ?\n",
            "= why did you put it there ?\n",
            "< why did you buy that ? <EOS>\n",
            "\n",
            "> ньютон видел как с дерева упало яблоко .\n",
            "= newton saw an apple fall off a tree .\n",
            "< the one as as as as as as as as as as as as as <EOS>\n",
            "\n",
            "> том звонил вчера утром .\n",
            "= tom called yesterday morning .\n",
            "< tom has a a . . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 24s (- 19m 37s) (5000 6%) 4.6485\n",
            "2m 47s (- 18m 6s) (10000 13%) 4.3255\n",
            "4m 11s (- 16m 45s) (15000 20%) 4.1221\n",
            "5m 35s (- 15m 23s) (20000 26%) 3.9367\n",
            "7m 0s (- 14m 1s) (25000 33%) 3.8610\n",
            "8m 25s (- 12m 38s) (30000 40%) 3.7773\n",
            "9m 49s (- 11m 13s) (35000 46%) 3.6779\n",
            "11m 14s (- 9m 50s) (40000 53%) 3.5939\n",
            "12m 39s (- 8m 26s) (45000 60%) 3.5096\n",
            "14m 3s (- 7m 1s) (50000 66%) 3.4935\n",
            "15m 28s (- 5m 37s) (55000 73%) 3.3950\n",
            "16m 53s (- 4m 13s) (60000 80%) 3.3408\n",
            "18m 19s (- 2m 49s) (65000 86%) 3.2744\n",
            "19m 43s (- 1m 24s) (70000 93%) 3.2215\n",
            "21m 8s (- 0m 0s) (75000 100%) 3.1852\n",
            "\n",
            "evaluate\n",
            "\n",
            "> краска на двери еще не высохла .\n",
            "= the paint on the door is not dry yet .\n",
            "< the is not to to . . <EOS>\n",
            "\n",
            "> я тебе полностью доверяю .\n",
            "= i trust you completely .\n",
            "< i ll you you . <EOS>\n",
            "\n",
            "> вы помните где оставили свои зонт ?\n",
            "= do you remember where you left your umbrella ?\n",
            "< do you have any the same ? <EOS>\n",
            "\n",
            "> том больше не ходит в школу .\n",
            "= tom doesn t go to school anymore .\n",
            "< tom didn t go to boston . <EOS>\n",
            "\n",
            "> может быть тебе лучше уити .\n",
            "= maybe you d better leave .\n",
            "< you can t be to . <EOS>\n",
            "\n",
            "> он поехал в школу на машине .\n",
            "= he drove to school .\n",
            "< he was in in in in . <EOS>\n",
            "\n",
            "> я и не знал что у вас такое есть .\n",
            "= i didn t even know that you had one .\n",
            "< i didn t know what you have a . <EOS>\n",
            "\n",
            "> используи возможности по максимуму .\n",
            "= make the best of your opportunities .\n",
            "< the is is a . <EOS>\n",
            "\n",
            "> том спел мне песню .\n",
            "= tom sang me a song .\n",
            "< tom will give me . <EOS>\n",
            "\n",
            "> поступок тома показался мне странным .\n",
            "= what tom did seemed strange to me .\n",
            "< tom s a the of . . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 22s (- 19m 8s) (5000 6%) 4.6120\n",
            "2m 42s (- 17m 39s) (10000 13%) 4.2393\n",
            "4m 4s (- 16m 16s) (15000 20%) 4.0516\n",
            "5m 25s (- 14m 56s) (20000 26%) 3.9155\n",
            "6m 48s (- 13m 36s) (25000 33%) 3.8339\n",
            "8m 11s (- 12m 16s) (30000 40%) 3.7661\n",
            "9m 34s (- 10m 56s) (35000 46%) 3.6700\n",
            "10m 57s (- 9m 35s) (40000 53%) 3.5830\n",
            "12m 21s (- 8m 14s) (45000 60%) 3.5170\n",
            "13m 44s (- 6m 52s) (50000 66%) 3.4460\n",
            "15m 8s (- 5m 30s) (55000 73%) 3.3803\n",
            "16m 32s (- 4m 8s) (60000 80%) 3.3398\n",
            "17m 56s (- 2m 45s) (65000 86%) 3.2825\n",
            "19m 19s (- 1m 22s) (70000 93%) 3.2274\n",
            "20m 43s (- 0m 0s) (75000 100%) 3.1816\n",
            "\n",
            "evaluate\n",
            "\n",
            "> я уверен что ты наидешь какои нибудь способ .\n",
            "= i m sure you ll find a way .\n",
            "< i m sure you re a . . . <EOS>\n",
            "\n",
            "> это было глупо с моеи стороны сделать такую ошибку .\n",
            "= it was stupid of me to make such a mistake .\n",
            "< it was a a to to the . . . <EOS>\n",
            "\n",
            "> я просто хотел пожелать удачи .\n",
            "= i just wanted to say good luck .\n",
            "< i wanted to to a . . <EOS>\n",
            "\n",
            "> было тридцать гостеи .\n",
            "= there were guests .\n",
            "< the was was a . . <EOS>\n",
            "\n",
            "> мне кажется я слышал как кто то открывает окно .\n",
            "= i think i heard somebody opening a window .\n",
            "< i think i think the same . <EOS>\n",
            "\n",
            "> том устал работать с мэри и ушел .\n",
            "= tom got tired of working with mary and quit .\n",
            "< tom asked mary to mary mary . <EOS>\n",
            "\n",
            "> том владелец магазина игрушек .\n",
            "= tom owns a toy store .\n",
            "< tom is to to . . <EOS>\n",
            "\n",
            "> как так вышло что мы разные ?\n",
            "= how come we re different ?\n",
            "< what do we we do ? ? <EOS>\n",
            "\n",
            "> у меня сегодня нет на это времени .\n",
            "= i don t have time to do that today .\n",
            "< i can t do this this . . <EOS>\n",
            "\n",
            "> я не знал что ты здесь будешь .\n",
            "= i didn t know you d be here .\n",
            "< i didn t know you re here . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "MeDDNpbOc50v",
        "outputId": "18346979-48ad-484b-80bf-ad9bcefdb1ca"
      },
      "source": [
        "exp5                = pd.read_csv(PATH8+'Att6.csv').iloc[:,[1,2,4,5]]\n",
        "exp5['Decoder']     = dec[:4]\n",
        "exp5['learn_rate']  = 0.003\n",
        "exp5                = exp5.iloc[:,[-1,0,1,2,3]]\n",
        "exp5"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learn_rate</th>\n",
              "      <th>Max_length</th>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>Decoder</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.265885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.280422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.185217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.181635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   learn_rate  Max_length RNN_Type Decoder      Loss\n",
              "0       0.003          20     LSTM     mlp  3.265885\n",
              "1       0.003          20     LSTM  scalar  3.280422\n",
              "2       0.003          20      GRU     mlp  3.185217\n",
              "3       0.003          20      GRU  scalar  3.181635"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_0UmxoRYuMG"
      },
      "source": [
        "#### 4.6.  Модель 6 - Предложения длиной от 1 до 20 слов / без привязки к шаблону / lr = 0.003"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnnjQhsZMKKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba10dd9-0710-42fd-d3d2-b48b273ef6b4"
      },
      "source": [
        "#  убираем фильтр до 3 слов\n",
        "test_model_hw_8(max_length_sent = 20, prefix = None,\n",
        "                learn_rate = 0.003, teach_force_ratio = 0.5, \n",
        "                num_iters = 75000,  every = 5000, num_file ='Att7')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 431097 sentence pairs\n",
            "Trimmed to 430522 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 54757\n",
            "eng 16278\n",
            "['я не думаю что ты права .', 'i don t believe you re right .']\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 23s (- 19m 30s) (5000 6%) 4.7588\n",
            "2m 47s (- 18m 6s) (10000 13%) 4.3590\n",
            "4m 11s (- 16m 46s) (15000 20%) 4.2292\n",
            "5m 37s (- 15m 27s) (20000 26%) 4.0898\n",
            "7m 2s (- 14m 4s) (25000 33%) 3.9550\n",
            "8m 28s (- 12m 42s) (30000 40%) 3.8692\n",
            "9m 53s (- 11m 18s) (35000 46%) 3.7959\n",
            "11m 18s (- 9m 53s) (40000 53%) 3.7174\n",
            "12m 43s (- 8m 29s) (45000 60%) 3.6444\n",
            "14m 9s (- 7m 4s) (50000 66%) 3.6158\n",
            "15m 34s (- 5m 39s) (55000 73%) 3.5611\n",
            "17m 1s (- 4m 15s) (60000 80%) 3.5068\n",
            "18m 25s (- 2m 50s) (65000 86%) 3.4248\n",
            "19m 51s (- 1m 25s) (70000 93%) 3.4046\n",
            "21m 18s (- 0m 0s) (75000 100%) 3.3474\n",
            "\n",
            "evaluate\n",
            "\n",
            "> меня внесли в черныи список .\n",
            "= i ve been blacklisted .\n",
            "< i m a to the . . <EOS>\n",
            "\n",
            "> том не очень часто это делал .\n",
            "= tom didn t do that very often .\n",
            "< tom didn t do that that that . <EOS>\n",
            "\n",
            "> я думаю тебе нужно больше есть .\n",
            "= i think that you need to eat more .\n",
            "< i think you need to do . . <EOS>\n",
            "\n",
            "> вы ничего не сделали .\n",
            "= you didn t do anything .\n",
            "< you re not a . . <EOS>\n",
            "\n",
            "> том не очень любит арбузы .\n",
            "= tom doesn t really like watermelon .\n",
            "< tom didn t have a good . <EOS>\n",
            "\n",
            "> когда вы поидете ?\n",
            "= when will you go ?\n",
            "< how many you have ? <EOS>\n",
            "\n",
            "> я приковал себя к одному из деревьев которые они собирались срубить .\n",
            "= i chained myself to one of the trees they were planning to cut down .\n",
            "< i ve been to to the the to the the . . . <EOS>\n",
            "\n",
            "> эти детали не будут обнародованы .\n",
            "= these details won t be published .\n",
            "< you don t need to . . <EOS>\n",
            "\n",
            "> я хочу чтобы ты меня поцеловал .\n",
            "= i want you to kiss me .\n",
            "< i want you to go to go . <EOS>\n",
            "\n",
            "> подозреваю что тебе это не понравится .\n",
            "= i suspect that you won t like it .\n",
            "< i don t think you ll do . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "LSTM\n",
            "\n",
            "training\n",
            "1m 21s (- 19m 2s) (5000 6%) 4.7874\n",
            "2m 42s (- 17m 34s) (10000 13%) 4.3275\n",
            "4m 4s (- 16m 16s) (15000 20%) 4.1537\n",
            "5m 27s (- 15m 0s) (20000 26%) 4.0424\n",
            "6m 50s (- 13m 41s) (25000 33%) 3.9733\n",
            "8m 14s (- 12m 22s) (30000 40%) 3.8710\n",
            "9m 38s (- 11m 1s) (35000 46%) 3.7705\n",
            "11m 3s (- 9m 40s) (40000 53%) 3.7060\n",
            "12m 27s (- 8m 18s) (45000 60%) 3.6128\n",
            "13m 52s (- 6m 56s) (50000 66%) 3.5666\n",
            "15m 16s (- 5m 33s) (55000 73%) 3.4866\n",
            "16m 40s (- 4m 10s) (60000 80%) 3.4774\n",
            "18m 4s (- 2m 46s) (65000 86%) 3.4061\n",
            "19m 29s (- 1m 23s) (70000 93%) 3.3546\n",
            "20m 53s (- 0m 0s) (75000 100%) 3.2884\n",
            "\n",
            "evaluate\n",
            "\n",
            "> том вернется в половине третьего .\n",
            "= tom will come back at .\n",
            "< tom is in the . <EOS>\n",
            "\n",
            "> может статься что люди израсходуют всю нефть на земле .\n",
            "= the time may come when people will have used up all the oil .\n",
            "< the s is the the to the the . . <EOS>\n",
            "\n",
            "> том богатыи мужчина .\n",
            "= tom is a rich man .\n",
            "< tom is a . <EOS>\n",
            "\n",
            "> у тома один ребенок .\n",
            "= tom has one kid .\n",
            "< tom has a . . <EOS>\n",
            "\n",
            "> тебе это понадобится .\n",
            "= you ll need that .\n",
            "< you ll be . <EOS>\n",
            "\n",
            "> сколько бы людеи ни говорило тому что он совершил ошибку он все равно настаивает что прав .\n",
            "= no matter how many people tell him he made a mistake tom still insists he s right .\n",
            "< the one as he was i d what i d he he he he he . <EOS>\n",
            "\n",
            "> возможно это то что мне нужно .\n",
            "= maybe that s what i need .\n",
            "< that s what i ll do . <EOS>\n",
            "\n",
            "> наши нужды богу известны .\n",
            "= god knows what we need .\n",
            "< the was a to . . <EOS>\n",
            "\n",
            "> я думаю вы чересчур оптимистичны .\n",
            "= i think you re overly optimistic .\n",
            "< i think you re you . <EOS>\n",
            "\n",
            "> почему мы не можем сделать это сегодня ?\n",
            "= why can t we do that today ?\n",
            "< why don t we do it ? <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  1\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 23s (- 19m 31s) (5000 6%) 4.6243\n",
            "2m 46s (- 18m 3s) (10000 13%) 4.2504\n",
            "4m 10s (- 16m 40s) (15000 20%) 4.0595\n",
            "5m 33s (- 15m 17s) (20000 26%) 3.8917\n",
            "6m 57s (- 13m 54s) (25000 33%) 3.7616\n",
            "8m 21s (- 12m 31s) (30000 40%) 3.6221\n",
            "9m 44s (- 11m 8s) (35000 46%) 3.5820\n",
            "11m 9s (- 9m 45s) (40000 53%) 3.4982\n",
            "12m 32s (- 8m 21s) (45000 60%) 3.4243\n",
            "13m 56s (- 6m 58s) (50000 66%) 3.3625\n",
            "15m 20s (- 5m 34s) (55000 73%) 3.3164\n",
            "16m 44s (- 4m 11s) (60000 80%) 3.2182\n",
            "18m 8s (- 2m 47s) (65000 86%) 3.1984\n",
            "19m 33s (- 1m 23s) (70000 93%) 3.1229\n",
            "20m 58s (- 0m 0s) (75000 100%) 3.0924\n",
            "\n",
            "evaluate\n",
            "\n",
            "> хлеб на столе .\n",
            "= the bread s on the table .\n",
            "< the your the . . <EOS>\n",
            "\n",
            "> у вас полно друзеи .\n",
            "= you have lots of friends .\n",
            "< you have a . . <EOS>\n",
            "\n",
            "> в начале бог создал небо и землю .\n",
            "= in the beginning god created the heaven and the earth .\n",
            "< there s is a the and and and and . <EOS>\n",
            "\n",
            "> том тебе не брат .\n",
            "= tom isn t your brother .\n",
            "< tom won t you . . <EOS>\n",
            "\n",
            "> том знает что полиция подозревает его .\n",
            "= tom knows that the police suspect him .\n",
            "< tom knows that he was him . <EOS>\n",
            "\n",
            "> бесценныи фарфор разлетелся на куски .\n",
            "= the priceless china shattered into fragments .\n",
            "< the people are in the . . <EOS>\n",
            "\n",
            "> собака тома спит у его постели .\n",
            "= tom s dog sleeps next to tom s bed .\n",
            "< tom tom tom his his . . <EOS>\n",
            "\n",
            "> том и мэри по настоящему ненавидят друг друга .\n",
            "= tom and mary really hate each other .\n",
            "< tom and mary are still with . <EOS>\n",
            "\n",
            "> я вас иногда не понимаю .\n",
            "= i don t understand you sometimes .\n",
            "< i ll never t you . <EOS>\n",
            "\n",
            "> я хочу посмотреть на что я способна .\n",
            "= i want to see what i m capable of .\n",
            "< i want to know what i m . <EOS>\n",
            "\n",
            "\n",
            "Max_length =  20\n",
            "\n",
            "Decoder =  2\n",
            "GRU\n",
            "\n",
            "training\n",
            "1m 22s (- 19m 14s) (5000 6%) 4.6072\n",
            "2m 42s (- 17m 35s) (10000 13%) 4.2378\n",
            "4m 2s (- 16m 11s) (15000 20%) 4.0442\n",
            "5m 24s (- 14m 52s) (20000 26%) 3.9239\n",
            "6m 46s (- 13m 33s) (25000 33%) 3.8434\n",
            "8m 8s (- 12m 12s) (30000 40%) 3.7439\n",
            "9m 31s (- 10m 52s) (35000 46%) 3.6506\n",
            "10m 54s (- 9m 32s) (40000 53%) 3.6135\n",
            "12m 16s (- 8m 11s) (45000 60%) 3.5036\n",
            "13m 39s (- 6m 49s) (50000 66%) 3.4495\n",
            "15m 2s (- 5m 28s) (55000 73%) 3.4194\n",
            "16m 25s (- 4m 6s) (60000 80%) 3.3220\n",
            "17m 48s (- 2m 44s) (65000 86%) 3.2675\n",
            "19m 10s (- 1m 22s) (70000 93%) 3.2312\n",
            "20m 33s (- 0m 0s) (75000 100%) 3.2046\n",
            "\n",
            "evaluate\n",
            "\n",
            "> нам нужно бежать .\n",
            "= we need to run .\n",
            "< we need to us . <EOS>\n",
            "\n",
            "> я же говорил тебе что том не умеет этого делать .\n",
            "= i told you tom couldn t do that .\n",
            "< i told tom you you t do that . <EOS>\n",
            "\n",
            "> это для меня слишком много .\n",
            "= this is too much for me .\n",
            "< that s a me of . . <EOS>\n",
            "\n",
            "> это наша страна .\n",
            "= this is our country .\n",
            "< it s a . . <EOS>\n",
            "\n",
            "> как сделать коробку ?\n",
            "= how do you make a box ?\n",
            "< how do do you ? ? <EOS>\n",
            "\n",
            "> почему ты всегда такая подозрительная ?\n",
            "= why are you always so suspicious ?\n",
            "< why did you know a ? ? <EOS>\n",
            "\n",
            "> том хорошии даивер .\n",
            "= tom is a good diver .\n",
            "< tom is a . . <EOS>\n",
            "\n",
            "> не думаю что том знает сколько будет стоить билет .\n",
            "= i don t think tom knows how much the ticket will cost .\n",
            "< i don t think tom knows what he is . <EOS>\n",
            "\n",
            "> том опять возвращается ?\n",
            "= is tom coming back again ?\n",
            "< does tom is a ? <EOS>\n",
            "\n",
            "> вы не знали что том друг мэри ?\n",
            "= didn t you know tom was a friend of mary s ?\n",
            "< didn t you know tom tom mary mary <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeDS5hq0_qH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "073d2a98-0283-4d0c-919c-1c4358751a2d"
      },
      "source": [
        "exp6                = pd.read_csv(PATH8+'Att7.csv').iloc[:,[1,2,4,5]]\n",
        "exp6['Decoder']     = dec[:4]\n",
        "exp6['learn_rate']  = 0.003\n",
        "exp6                = exp6.iloc[:,[-1,0,1,2,3]]\n",
        "exp6"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learn_rate</th>\n",
              "      <th>Max_length</th>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>Decoder</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.347446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.288415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.092382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.204575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   learn_rate  Max_length RNN_Type Decoder      Loss\n",
              "0       0.003          20     LSTM     mlp  3.347446\n",
              "1       0.003          20     LSTM  scalar  3.288415\n",
              "2       0.003          20      GRU     mlp  3.092382\n",
              "3       0.003          20      GRU  scalar  3.204575"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhqUtdf4kOtL"
      },
      "source": [
        "### 5. Обобщение результатов экспериментов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "3l0kfqPIkYRo",
        "outputId": "295d5209-fd7a-45f7-894c-bab2a8044cc2"
      },
      "source": [
        "results = pd.concat([exp1, exp2, exp3, exp4, exp5, exp6]).reset_index(drop=True)\n",
        "results#.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learn_rate</th>\n",
              "      <th>Max_length</th>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>Decoder</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>1.630128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>1.684131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>RNN</td>\n",
              "      <td>mlp</td>\n",
              "      <td>24.655075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>RNN</td>\n",
              "      <td>scalar</td>\n",
              "      <td>17.377365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>22.233171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.147843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.050</td>\n",
              "      <td>7</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>2.374869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.050</td>\n",
              "      <td>7</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>2.324447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.050</td>\n",
              "      <td>7</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>19.445005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.050</td>\n",
              "      <td>7</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>15.190802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>2.994014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>24.058059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.050</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>28.091668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.001</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.834810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.001</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.813181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.001</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.600392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.001</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.739083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.265885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.280422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.185217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.181635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.347446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.288415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>mlp</td>\n",
              "      <td>3.092382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.003</td>\n",
              "      <td>20</td>\n",
              "      <td>GRU</td>\n",
              "      <td>scalar</td>\n",
              "      <td>3.204575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    learn_rate  Max_length RNN_Type Decoder       Loss\n",
              "0        0.050          20     LSTM     mlp   1.630128\n",
              "1        0.050          20     LSTM  scalar   1.684131\n",
              "2        0.050          20      RNN     mlp  24.655075\n",
              "3        0.050          20      RNN  scalar  17.377365\n",
              "4        0.050          20      GRU     mlp  22.233171\n",
              "5        0.050          20      GRU  scalar   3.147843\n",
              "6        0.050           7     LSTM     mlp   2.374869\n",
              "7        0.050           7     LSTM  scalar   2.324447\n",
              "8        0.050           7      GRU     mlp  19.445005\n",
              "9        0.050           7      GRU  scalar  15.190802\n",
              "10       0.050          20     LSTM     mlp   2.994014\n",
              "11       0.050          20     LSTM  scalar   3.025424\n",
              "12       0.050          20      GRU     mlp  24.058059\n",
              "13       0.050          20      GRU  scalar  28.091668\n",
              "14       0.001          20     LSTM     mlp   3.834810\n",
              "15       0.001          20     LSTM  scalar   3.813181\n",
              "16       0.001          20      GRU     mlp   3.600392\n",
              "17       0.001          20      GRU  scalar   3.739083\n",
              "18       0.003          20     LSTM     mlp   3.265885\n",
              "19       0.003          20     LSTM  scalar   3.280422\n",
              "20       0.003          20      GRU     mlp   3.185217\n",
              "21       0.003          20      GRU  scalar   3.181635\n",
              "22       0.003          20     LSTM     mlp   3.347446\n",
              "23       0.003          20     LSTM  scalar   3.288415\n",
              "24       0.003          20      GRU     mlp   3.092382\n",
              "25       0.003          20      GRU  scalar   3.204575"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "sjcLeQlNkt3w",
        "outputId": "14c5058b-3bc8-4dd7-ed5f-e670e4204f60"
      },
      "source": [
        "temp_table = results[(results.index>1)&\n",
        "                     (results.index<22)&\n",
        "                     (results.Max_length==20)&\n",
        "                     (results.RNN_Type=='LSTM')]\n",
        "\n",
        "fine_table(pd.pivot_table(  temp_table,\n",
        "                            values  = 'Loss',\n",
        "                            columns = 'learn_rate',\n",
        "                            index   = 'Decoder',\n",
        "                            aggfunc = 'max'\n",
        "                         ), \n",
        "           title = 'Оценка качества модели LSTM', \n",
        "           x_l='learning rate', y_l = 'Decoder_type')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Ss8I_E7QpLFY",
        "outputId": "52438837-a8b6-4732-ea3c-7c9caf1def7f"
      },
      "source": [
        "temp_table = results[(results.index>1)&\n",
        "                     (results.index<22)&\n",
        "                     (results.Max_length==20)&\n",
        "                     (results.RNN_Type=='GRU')]\n",
        "\n",
        "fine_table(pd.pivot_table(  temp_table,\n",
        "                            values  = 'Loss',\n",
        "                            columns = 'learn_rate',\n",
        "                            index   = 'Decoder',\n",
        "                            aggfunc = 'max'\n",
        "                         ), \n",
        "           title = 'Оценка качества модели GRU', \n",
        "           x_l='learning rate', y_l = 'Decoder_type')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfHBJPphunoN"
      },
      "source": [
        "temp_table = results[(results.index>1)&\n",
        "                     (results.index<22)&\n",
        "                     (results.Max_length==20)]\n",
        "\n",
        "fine_table(pd.pivot_table(  temp_table,\n",
        "                            values  = 'Loss',\n",
        "                            columns = 'Decoder',\n",
        "                            index   = ['RNN_Type', 'learn_rate'],\n",
        "                            aggfunc = 'max'\n",
        "                         ), \n",
        "           title = 'Оценка качества модели от типа декодера Attention', \n",
        "           x_l='Decoder_type', y_l = 'RNN / learning rate')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cqwR7h2v5HL"
      },
      "source": [
        "temp_table = results[(results.index>1)&\n",
        "                     (results.index<22)&\n",
        "                     (results.Max_length==20)]\n",
        "\n",
        "fine_table(pd.pivot_table(  temp_table,\n",
        "                            values  = 'Loss',\n",
        "                            columns = 'Decoder',\n",
        "                            index   = ['RNN_Type', 'learn_rate'],\n",
        "                            aggfunc = 'max'\n",
        "                         ), \n",
        "           title = 'Оценка качества модели от типа декодера Attention', \n",
        "           x_l='Decoder_type', y_l = 'RNN / learning rate')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "9jEO563RLSnp",
        "outputId": "5b5bcf01-73f6-4825-dd75-0d9755af19a4"
      },
      "source": [
        "temp_table = results[(results.index>1)&\n",
        "                     (results.index<22)&\n",
        "                     (results.Max_length==20)]\n",
        "temp_table.head(1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learn_rate</th>\n",
              "      <th>Max_length</th>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>Decoder</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.05</td>\n",
              "      <td>20</td>\n",
              "      <td>RNN</td>\n",
              "      <td>mlp</td>\n",
              "      <td>24.655075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   learn_rate  Max_length RNN_Type Decoder       Loss\n",
              "2        0.05          20      RNN     mlp  24.655075"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wapBhzf-LhaK"
      },
      "source": [
        "fine_table(pd.pivot_table(  temp_table,\n",
        "                            values  = 'Loss',\n",
        "                            columns = 'Decoder',\n",
        "                            index   = ['RNN_Type', 'learn_rate'],\n",
        "                            aggfunc = 'max'\n",
        "                         ), \n",
        "           title = 'Оценка качества модели от типа декодера Attention', \n",
        "           x_l='Decoder_type', y_l = 'RNN / learning rate')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "gcFi5__eLkTP",
        "outputId": "a7c83178-5342-43b8-d8f7-aa72367ee1f6"
      },
      "source": [
        "pp = pd.pivot_table(  temp_table,\n",
        "                            values  = 'Loss',\n",
        "                            columns = 'Decoder',\n",
        "                            index   = ['RNN_Type', 'learn_rate'],\n",
        "                            aggfunc = 'max'\n",
        "                         )\n",
        "pp"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Decoder</th>\n",
              "      <th>mlp</th>\n",
              "      <th>scalar</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RNN_Type</th>\n",
              "      <th>learn_rate</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">GRU</th>\n",
              "      <th>0.001</th>\n",
              "      <td>3.600392</td>\n",
              "      <td>3.739083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.003</th>\n",
              "      <td>3.185217</td>\n",
              "      <td>3.181635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.050</th>\n",
              "      <td>24.058059</td>\n",
              "      <td>28.091668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">LSTM</th>\n",
              "      <th>0.001</th>\n",
              "      <td>3.834810</td>\n",
              "      <td>3.813181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.003</th>\n",
              "      <td>3.265885</td>\n",
              "      <td>3.280422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.050</th>\n",
              "      <td>2.994014</td>\n",
              "      <td>3.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RNN</th>\n",
              "      <th>0.050</th>\n",
              "      <td>24.655075</td>\n",
              "      <td>17.377365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Decoder                    mlp     scalar\n",
              "RNN_Type learn_rate                      \n",
              "GRU      0.001        3.600392   3.739083\n",
              "         0.003        3.185217   3.181635\n",
              "         0.050       24.058059  28.091668\n",
              "LSTM     0.001        3.834810   3.813181\n",
              "         0.003        3.265885   3.280422\n",
              "         0.050        2.994014   3.025424\n",
              "RNN      0.050       24.655075  17.377365"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0RrQ5c3MMQh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}